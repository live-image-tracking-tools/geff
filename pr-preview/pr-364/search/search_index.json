{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to geff!","text":"<p>GEFF is a specification for a file format for exchanging spatial graph data. It is not intended to be mutable, editable, chunked, or optimized for use in an application setting.</p> <p>This repository contains two packages: - <code>geff-spec</code> is the specification of GEFF metadata written with <code>pydantic</code> <code>BaseModels</code> which are exported to a json schema for use in other languages. - <code>geff</code> is the python library that reads and writes GEFF files to and from several python in-memory graph data structures (<code>networkx</code>, <code>rustworkx</code> and <code>spatial-graph</code>).</p> <p>Learn more in the documentation or check out the source code.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install geff\n</code></pre>"},{"location":"command-line-tools/","title":"Command line tools","text":""},{"location":"command-line-tools/#geff","title":"geff","text":"<p>GEFF Command Line Interface</p> <p>Usage:</p> <pre><code> [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <pre><code>  --install-completion  Install completion for the current shell.\n  --show-completion     Show completion for the current shell, to copy it or\n                        customize the installation.\n</code></pre>"},{"location":"command-line-tools/#convert-ctc","title":"convert-ctc","text":"<p>Convert a CTC data directory to a GEFF file.</p> <p>Usage:</p> <pre><code> convert-ctc [OPTIONS] CTC_PATH GEFF_PATH\n</code></pre> <p>Options:</p> <pre><code>  CTC_PATH                      The path to the directory containing ctc\n                                tracks (man_track.txt or res_track.txt), e.g.\n                                data/01_GT/TRA or data/01_RES  \\[required]\n  GEFF_PATH                     Path to save the output geff, including the\n                                geff directory name (eg.\n                                ~/folder/folder/data.zarr/tracks.geff)\n                                \\[required]\n  --segm-path PATH              The path to export the segmentation file, if\n                                not provided, it won't be exported.\n  --input-image-dir PATH        The path to the input image directory. If not\n                                provided, it won't be exported.\n  --output-image-path PATH      The path to export the image file, if not\n                                provided, it won't be exported.\n  --tczyx / --no-tczyx          Expand data to make it (T, C, Z, Y, X)\n                                otherwise it's (T,) + Frame shape.  \\[default:\n                                no-tczyx]\n  --overwrite / --no-overwrite  Whether to overwrite the GEFF file if it\n                                already exists.  \\[default: no-overwrite]\n  --zarr-format INTEGER         The version of zarr to write.  \\[default: 2]\n</code></pre>"},{"location":"command-line-tools/#convert-to-csv","title":"convert-to-csv","text":"<p>Usage:</p> <pre><code> convert-to-csv [OPTIONS] STORE OUTPATH\n</code></pre> <p>Options:</p> <pre><code>  STORE    Path to geff group to convert  \\[required]\n  OUTPATH  Path to save output csvs. Any file extension will be stripped and\n           replaced with '-nodes.csv' and '-edges.csv'  \\[required]\n</code></pre>"},{"location":"command-line-tools/#convert-trackmate-xml","title":"convert-trackmate-xml","text":"<p>Convert a TrackMate XML file to a GEFF file.</p> <p>Usage:</p> <pre><code> convert-trackmate-xml [OPTIONS] XML_PATH GEFF_PATH\n</code></pre> <p>Options:</p> <pre><code>  XML_PATH                        The path to the TrackMate XML file\n                                  \\[required]\n  GEFF_PATH                       Path to save the output geff, including the\n                                  geff directory name (eg.\n                                  ~/folder/folder/data.zarr/tracks.geff)\n                                  \\[required]\n  --discard-filtered-spots / --no-discard-filtered-spots\n                                  True to discard the spots filtered out in\n                                  TrackMate, False otherwise.  \\[default: no-\n                                  discard-filtered-spots]\n  --discard-filtered-tracks / --no-discard-filtered-tracks\n                                  True to discard the tracks filtered out in\n                                  TrackMate, False otherwise.  \\[default: no-\n                                  discard-filtered-tracks]\n  --overwrite / --no-overwrite    Whether to overwrite the GEFF file if it\n                                  already exists.  \\[default: no-overwrite]\n  --zarr-format INTEGER           The version of zarr to write.  \\[default: 2]\n</code></pre>"},{"location":"command-line-tools/#info","title":"info","text":"<p>Display information about a GEFF file.</p> <p>Usage:</p> <pre><code> info [OPTIONS] INPUT_PATH\n</code></pre> <p>Options:</p> <pre><code>  INPUT_PATH  Path to the GEFF folder, e.g. data.zarr/tracks.geff  \\[required]\n</code></pre>"},{"location":"command-line-tools/#validate","title":"validate","text":"<p>Validate a GEFF file.</p> <p>Usage:</p> <pre><code> validate [OPTIONS] INPUT_PATH\n</code></pre> <p>Options:</p> <pre><code>  INPUT_PATH  Path to the GEFF folder, e.g. data.zarr/tracks.geff  \\[required]\n</code></pre>"},{"location":"command-line-tools/#running-command-line-tools","title":"Running command line tools","text":"<p>Without pip-installing <code>geff</code>, you can run the tools as  <pre><code>uvx geff -h # by uv\n# or \npipx geff -h # by pipx\n</code></pre></p>"},{"location":"command-line-tools/#running-command-with-a-developmental-build","title":"Running command with a developmental build","text":"<p>You can run the command line tool for your local build as </p> <pre><code>pip install -e .\ngeff -h\n</code></pre>"},{"location":"compatibility/","title":"Compatible Libraries","text":"<p>The following libraries can read and/or write GEFF files:</p> <ul> <li><code>motile-tracker</code></li> <li><code>traccuracy</code></li> <li><code>ultrack</code></li> <li><code>track_gardener</code></li> <li><code>laptrack</code></li> <li><code>trackastra</code></li> <li><code>TrackMate</code></li> <li><code>InTRACKtive</code></li> <li><code>tracksdata</code></li> <li><code>napari-geff</code></li> </ul>"},{"location":"convert/","title":"Conversion to GEFF","text":"<p>If you already have tracking data stored in another format, we have some functions for converting data to GEFF.</p>"},{"location":"convert/#cell-tracking-challenge-ctc","title":"Cell Tracking Challenge (CTC)","text":"<p>To use the <code>geff</code> cli to convert CTC data to GEFF, see the docs for <code>geff convert-ctc</code>.</p> <p>To use the <code>geff</code> python API, see the docs for <code>ctc_tiffs_to_zarr</code> and <code>from_ctc_to_geff</code>.</p>"},{"location":"convert/#trackmate-xml","title":"Trackmate XML","text":"<p>Note</p> <p>Conversion from TrackMate XML to GEFF is currently NOT lossless, but we are working on it.     The output GEFF is missing:</p> <ul> <li>for each spot, the coordinates of its ROI (segmentation)</li> <li>for each track, the value of its features (e.g., <code>TRACK_DISPLACEMENT</code>, <code>TRACK_MEAN_SPEED</code>)</li> </ul> <p>To convert a Trackmat XML file to GEFF using the <code>geff</code> cli, see the docs for <code>geff convert-trackmate-xml</code>.</p> <p>To use the <code>geff</code> python API, see the docs for <code>from_trackmate_xml_to_geff</code>.</p>"},{"location":"convert/#acetree","title":"AceTree","text":"<p>An example of how to convert AceTree data to a GEFF is available here. </p>"},{"location":"specification/","title":"Geff specification","text":"<p>The graph exchange file format is <code>zarr</code> based. A graph is stored in a zarr group, which can have any name. However the name of the group can include the <code>.geff</code> suffix to indicate that the group contains <code>geff</code> data. This allows storing multiple <code>geff</code> graphs inside the same zarr root directory. A <code>geff</code> group is identified by the presence of a <code>geff</code> key in the <code>.zattrs</code>. Other <code>geff</code> metadata is also stored in the <code>.zattrs</code> file of the <code>geff</code> group, nested under the <code>geff</code> key. The <code>geff</code> group must contain a <code>nodes</code> group and an <code>edges</code> group (albeit both can be empty). <code>geff</code> graphs have the option to provide properties for <code>nodes</code> and <code>edges</code>.</p> <p><code>geff</code> graphs have the option to provide time and spatial dimensions as special attributes. These attributes are specified in the <code>axes</code> section of the metadata, inspired by the OME-zarr <code>axes</code> specification.</p>"},{"location":"specification/#zarr-specification","title":"Zarr specification","text":"<p>Currently, <code>geff</code> supports zarr specifications 2 and 3. However, <code>geff</code> will default to writing specification 2 because graphs written to the zarr v3 spec will not be compatible with all applications. When zarr 3 is more fully adopted by other libraries and tools, we will move to a zarr spec 3 default.</p>"},{"location":"specification/#geff_spec.GeffMetadata","title":"geff_spec.GeffMetadata","text":"<p>               Bases: <code>BaseModel</code></p> <p>Geff metadata schema to validate the attributes json file in a geff zarr</p> <p>Parameters:</p> <ul> <li> <code>geff_version</code>               (<code>str</code>, default:                   <code>'1.1'</code> )           \u2013            <p>Geff version string following semantic versioning (MAJOR.MINOR.PATCH), optionally with .devN and/or +local parts (e.g., 0.3.1.dev6+g61d5f18). If not provided, the version will be set to the current geff package version.</p> </li> <li> <code>directed</code>               (<code>bool</code>)           \u2013            <p>True if the graph is directed, otherwise False.</p> </li> <li> <code>axes</code>               (<code>list[Axis] | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional list of <code>Axis</code> objects defining the axes of each node             in the graph. The axes list is modeled after the             OME-zarr             specifications and is used to identify spatio-temporal properties on the             graph nodes. If the same names are used in the axes metadata of the             related image or segmentation data, applications can use this information             to align graph node locations with image data.             The order of the axes in the list is meaningful. For one, any downstream             properties that are an array of values with one value per (spatial) axis             will be in the order of the axis list (filtering to only the spatial axes by             the <code>type</code> field if needed). Secondly, if associated image or segmentation             data does not have axes metadata, the order of the spatiotemporal axes is a             good default guess for aligning the graph and the image data, although there             is no way to denote the channel dimension in the graph spec. If you are             writing out a geff with an associated segmentation and/or image dataset, we             highly recommend providing the axis names for your segmentation/image using             the OME-zarr spec, including channel dimensions if needed.</p> </li> <li> <code>node_props_metadata</code>               (<code>dict[str, PropMetadata]</code>)           \u2013            <p>Metadata for node properties. The keys are the property identifiers, and the values are PropMetadata objects describing the properties.There must be one entry for each node property.</p> </li> <li> <code>edge_props_metadata</code>               (<code>dict[str, PropMetadata]</code>)           \u2013            <p>Metadata for edge properties. The keys are the property identifiers, and the values are PropMetadata objects describing the properties.There must be one entry for each edge property.</p> </li> <li> <code>sphere</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Name of the optional <code>sphere</code> property.</p> <p>A sphere is defined by</p> <ul> <li>a center point, already given by the <code>space</code> type properties</li> <li>a radius scalar, stored in this property</li> </ul> </li> <li> <code>ellipsoid</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Name of the <code>ellipsoid</code> property.</p> <p>An ellipsoid is assumed to be in the same coordinate system as the <code>space</code> type properties.</p> <p>It is defined by</p> <ul> <li>a center point \\(c\\), already given by the <code>space</code> type properties</li> <li>a covariance matrix \\(\\Sigma\\), symmetric and positive-definite, stored in this   property as a <code>2x2</code>/<code>3x3</code> array.</li> </ul> <p>To plot the ellipsoid:</p> <ul> <li>Compute the eigendecomposition of the covariance matrix \\(\\Sigma = Q \\Lambda Q^{\\top}\\)</li> <li>Sample points \\(z\\) on the unit sphere</li> <li>Transform the points to the ellipsoid by \\(x = c + Q \\Lambda^{(1/2)} z\\).</li> </ul> </li> <li> <code>track_node_props</code>               (<code>dict[Literal['lineage', 'tracklet'], str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Node properties denoting tracklet and/or lineage IDs. A tracklet is defined as a simple path of connected nodes where the initiating node has any incoming degree and outgoing degree at most 1, and the terminating node has incoming degree at most 1 and any outgoing degree, and other nodes along the path have in/out degree of 1. Each tracklet must contain the maximal set of connected nodes that match this definition - no sub-tracklets. A lineage is defined as a weakly connected component on the graph. The dictionary can store one or both of 'tracklet' or 'lineage' keys.</p> </li> <li> <code>related_objects</code>               (<code>list[RelatedObject] | None</code>, default:                   <code>None</code> )           \u2013            <p>A list of dictionaries of related objects such as labels or images. Each dictionary must contain 'type', 'path', and optionally 'label_prop' properties. The 'type' represents the data type. 'labels' and 'image' should be used for label and image objects, respectively. Other types are also allowed, The 'path' should be relative to the geff zarr-attributes file. It is strongly recommended all related objects are stored as siblings of the geff group within the top-level zarr group. The 'label_prop' is only valid for type 'labels' and specifies the node property that will be used to identify the labels in the related object.</p> </li> <li> <code>display_hints</code>               (<code>DisplayHint | None</code>, default:                   <code>None</code> )           \u2013            <p>Metadata indicating how spatiotemporal axes are displayed by a viewer</p> </li> <li> <code>extra</code>               (<code>dict[str, Any]</code>, default:                   <code>&lt;class 'dict'&gt;</code> )           \u2013            <p>The optional <code>extra</code> object is a free-form dictionary that can hold any additional, application-specific metadata that is not covered by the core geff schema. Users may place arbitrary keys and values inside <code>extra</code> without fear of clashing with future reserved fields. Although the core <code>geff</code> reader makes these attributes available, their meaning and use are left entirely to downstream applications.</p> </li> </ul>"},{"location":"specification/#the-nodes-group","title":"The <code>nodes</code> group","text":"<p>The nodes group will contain an <code>ids</code> array and optionally a <code>props</code> group.</p>"},{"location":"specification/#the-ids-array","title":"The <code>ids</code> array","text":"<p>The <code>nodes\\ids</code> array is a 1D array of node IDs of length <code>N</code> &gt;= 0, where <code>N</code> is the number of nodes in the graph. Node ids must be unique. Node IDs must have an integer dtype. For large graphs, <code>int64</code> might be necessary to provide enough range for every node to have a unique ID. In the minimal case of an empty graph, the <code>ids</code> array will be present but empty.</p>"},{"location":"specification/#the-props-group-and-node-property-groups","title":"The <code>props</code> group and <code>node property</code> groups","text":"<p>The <code>nodes\\props</code> group is optional and will contain one or more <code>node property</code> groups, each with a <code>values</code> array and an optional <code>missing</code> array.</p> <ul> <li> <p><code>values</code> arrays can be any zarr supported dtype, and can be N-dimensional. The first dimension of the <code>values</code> array must have the same length as the node <code>ids</code> array, such that each row of the property <code>values</code> array stores the property for the node at that index in the ids array. String  values will be stored according to the zarr-extensions string specification - as variable length UTF8 strings.</p> </li> <li> <p>The <code>missing</code> array is an optional, a one dimensional boolean array to support properties that are not present on all nodes. A <code>1</code> at an index in the <code>missing</code> array indicates that the <code>value</code> of that property for the node at that index is None, and the value in the <code>values</code> array at that index should be ignored. If the <code>missing</code> array is not present, that means that all nodes have values for the property.</p> </li> <li> <p>Geff provides special support for spatio-temporal properties, although they are not required. When <code>axes</code> are specified in the <code>geff</code> metadata, each axis name identifies a spatio-temporal property. Spatio-temporal properties are not allowed to have missing arrays. Otherwise, they are identical to other properties from a storage specification perspective.</p> </li> <li> <p>The <code>seg_id</code> property is an optional, special node property that stores the segmenatation label for each node. The <code>seg_id</code> values do not need to be unique, in case labels are repeated between time points. If the <code>seg_id</code> property is not present, it is assumed that the graph is not associated with a segmentation.</p> </li> <li> <p>Geff provides special support for predefined shape properties, although they are not required. These currently include: <code>sphere</code>, <code>ellipsoid</code>. Values can be marked as <code>missing</code>, and a geff graph may contain multiple different shape properties. Units of shapes are assumed to be the same as the units on the spatial axes. Otherwise, shape properties are identical to other properties from a storage specification perspective. - <code>sphere</code>: Hypersphere in n spatial dimensions, defined by a scalar radius. - <code>ellipsoid</code>: Defined by a symmetric positive-definite covariance matrix, whose dimensionality is assumed to match the spatial axes.</p> </li> </ul> <p>Note</p> <p>When writing a graph with missing properties to the geff format, you must fill in a dummy value in the <code>values</code> array for the nodes that are missing the property, in order to keep the indices aligned with the node ids.</p>"},{"location":"specification/#variable-length-properties","title":"Variable length properties","text":"<p>While most properties can be represented as normal arrays, where each node has a property of the same shape, the specification also supports properties where each node can have an array property of a variable shape. This is useful for properties such as polygons, meshes, or crops of bounding boxes. </p> <p>Variable length properties will have a <code>data</code> array in addition to the <code>values</code> and <code>missing</code> arrays. For variable length properties, the <code>data</code> array will contain a 1D flattened array of the actual values for all the nodes. The <code>values</code> array will contain the offset and shape of the relevant section of data in the <code>data</code> array.</p> <p></p>"},{"location":"specification/#the-edges-group","title":"The <code>edges</code> group","text":"<p>Similar to the <code>nodes</code> group, the <code>edges</code> group will contain an <code>ids</code> array and an optional <code>props</code> group.</p>"},{"location":"specification/#the-ids-array_1","title":"The <code>ids</code> array","text":"<p>The <code>edges\\ids</code> array is a 2D array with the same dtype as the <code>nodes\\ids</code> array. It has shape <code>(E, 2)</code>, where <code>E</code> is the number of edges in the graph. If there are no edges in the graph, the edge group and <code>ids</code> array must be present with shape <code>(0, 2)</code>. All elements in the <code>edges\\ids</code> array must also be present in the <code>nodes\\ids</code> array, and the data types of the two id arrays must match. Each row represents an edge between two nodes. For directed graphs, the first column is the source nodes and the second column holds the target nodes. For undirected graphs, the order is arbitrary. Edges should be unique (no multiple edges between the same two nodes) and edges from a node to itself are not supported.</p>"},{"location":"specification/#the-props-group-and-edge-property-groups","title":"The <code>props</code> group and <code>edge property</code> groups","text":"<p>The <code>edges\\props</code> group will contain zero or more <code>edge property</code> groups, each with a <code>values</code> array and an optional <code>missing</code> array. Variable length edge properties operate the same as variable length node properties, with an additional <code>data</code> array that the <code>values</code> array refers to.</p> <ul> <li><code>values</code> arrays can be any zarr supported dtype, and can be N-dimensional. The first dimension of the <code>values</code> array must have the same length as the <code>edges\\ids</code> array, such that each row of the property <code>values</code> array stores the property for the edge at that index in the ids array.</li> <li>The <code>missing</code> array is an optional, a one dimensional boolean array to support properties that are not present on all edges. A <code>1</code> at an index in the <code>missing</code> array indicates that the <code>value</code> of that property for the edge at that index is missing, and the value in the <code>values</code> array at that index should be ignored. If the <code>missing</code> array is not present, that means that all edges have values for the property.</li> </ul> <p>The <code>edges/props</code> is optional. If you do not have any edge properties, the <code>edges\\props</code> can be absent.</p>"},{"location":"specification/#example-file-structure-and-metadata","title":"Example file structure and metadata","text":"<p>Here is a schematic of the expected file structure.</p> <pre><code>/path/to.zarr\n    /tracking_graph.geff\n        .zattrs  # graph metadata with `geff_version`\n        nodes/\n            ids  # shape: (N,)  dtype: uint64\n            props/\n                t/\n                    values # shape: (N,) dtype: uint16\n                z/\n                    values # shape: (N,) dtype: float32\n                y/\n                    values # shape: (N,) dtype: float32\n                x/\n                    values # shape: (N,) dtype: float32\n                radius/\n                    values # shape: (N,) dtype: int | float\n                    missing # shape: (N,) dtype: bool\n                covariance3d/\n                    values # shape: (N, 3, 3) dtype: float\n                    missing # shape: (N,) dtype: bool\n                color/\n                    values # shape: (N, 4) dtype: float32\n                    missing # shape: (N,) dtype: bool\n                polygon/\n                    data # shape: (V,) dtype: any, V is the length of all the flattened entries\n                    values # shape: (N, ndim + 1) dtype: int64, ndim is number of dimensions in each entry array\n                    missing # shape: (N,) dtype: bool\n        edges/\n            ids  # shape: (E, 2) dtype: uint64\n            props/\n                distance/\n                    values # shape: (E,) dtype: float32\n                score/\n                    values # shape: (E,) dtype: float32\n                    missing # shape: (E,) dtype: bool\n    # optional:\n    /segmentation\n\n    # unspecified, but totally okay:\n    /raw\n</code></pre> <p>This is a geff metadata zattrs file that matches the above example structure.</p> <pre><code>// /path/to.zarr/tracking_graph/.zattrs\n{\n  \"geff\": {\n    \"directed\": true,\n    \"geff_version\": \"0.1.3\",\n    // axes are optional\n    \"axes\": [\n      { \"name\": \"t\", \"type\": \"time\", \"unit\": \"second\", \"min\": 0, \"max\": 125 },\n      {\n        \"name\": \"z\",\n        \"type\": \"space\",\n        \"unit\": \"micrometer\",\n        \"min\": 1523.36,\n        \"max\": 4398.1\n      },\n      {\n        \"name\": \"y\",\n        \"type\": \"space\",\n        \"unit\": \"micrometer\",\n        \"min\": 81.667,\n        \"max\": 1877.7\n      },\n      {\n        \"name\": \"x\",\n        \"type\": \"space\",\n        \"unit\": \"micrometer\",\n        \"min\": 764.42,\n        \"max\": 2152.3\n      }\n    ],\n    // predefined node attributes for storing detections as spheres or ellipsoids\n    \"sphere\": \"radius\", // optional\n    \"ellipsoid\": \"covariance3d\", // optional\n    \"display_hints\": {\n      \"display_horizontal\": \"x\",\n      \"display_vertical\": \"y\",\n      \"display_depth\": \"z\",\n      \"display_time\": \"t\"\n    },\n    \"node_props_metadata\": {\n      \"t\": {\n        \"identifier\": \"t\",\n        \"dtype\": \"uint16\",\n        \"varlength\": false,\n        \"unit\": \"second\"\n      },\n      \"z\": {\n        \"identifier\": \"z\",\n        \"dtype\": \"float32\",\n        \"varlength\": false,\n        \"unit\": \"micrometer\"\n      },\n      \"y\": {\n        \"identifier\": \"y\",\n        \"dtype\": \"float32\",\n        \"varlength\": false,\n        \"unit\": \"micrometer\"\n      },\n      \"x\": {\n        \"identifier\": \"x\",\n        \"dtype\": \"float32\",\n        \"varlength\": false,\n        \"unit\": \"micrometer\"\n      },\n      \"radius\": {\n        \"identifier\": \"radius\",\n        \"dtype\": \"float32\",\n        \"varlength\": false,\n        \"unit\": \"micrometer\"\n      },\n      \"covariance3d\": {\n        \"identifier\": \"covariance3d\",\n        \"dtype\": \"float32\",\n        \"varlength\": false\n      },\n      \"color\": { \"identifier\": \"color\", \"dtype\": \"float32\", \"varlength\": false }\n    },\n    \"edge_props_metadata\": {\n      \"distance\": {\n        \"identifier\": \"distance\",\n        \"dtype\": \"float32\",\n        \"varlength\": false\n      },\n      \"score\": { \"identifier\": \"score\", \"dtype\": \"float32\", \"varlength\": false }\n    },\n    // node attributes corresponding to tracklet and/or lineage IDs\n    \"track_node_props\": {\n      \"lineage\": \"ultrack_lineage_id\",\n      \"tracklet\": \"ultrack_id\"\n    },\n    \"related_objects\": [\n      {\n        \"type\": \"labels\",\n        \"path\": \"../segmentation/\",\n        \"label_prop\": \"seg_id\"\n      },\n      {\n        \"type\": \"image\",\n        \"path\": \"../raw/\"\n      }\n    ],\n    // optional coordinate transformation is defined as homogeneous coordinates\n    // It is expected to be a (D+1)x(D+1) matrix where D is the number of axes\n    \"affine\": [\n      [1, 0, 0, 0, 0],\n      [0, 1, 0, 0, 0],\n      [0, 0, 1, 0, 0],\n      [0, 0, 0, 1, 0],\n      [0, 0, 0, 0, 1]\n    ],\n    // custom other things must be placed **inside** the extra attribute\n    \"extra\": {\n      // ...\n    }\n  }\n}\n</code></pre> <p>Minimal geff metadata must have <code>version</code> and <code>directed</code> fields under a <code>geff</code> field, as well as empty <code>node_props_metadata</code> and <code>edge_props_metadata</code> fields.</p> <pre><code>{\n  \"geff\": {\n    \"version\": \"0.0.0\",\n    \"directed\": false,\n    \"node_props_metadata\": {},\n    \"edge_props_metadata\": {}\n  }\n}\n</code></pre>"},{"location":"tips-and-tricks/","title":"Tips and Tricks","text":""},{"location":"tips-and-tricks/#loading-a-subset-of-a-geff","title":"Loading a subset of a GEFF","text":"<p>Using a lower level component (<code>GeffReader</code>) of the <code>geff</code> API, it is possible to load a subset of a graph based on a mask that is applied either to nodes or edges. </p>"},{"location":"tips-and-tricks/#loading-a-subset-of-properties","title":"Loading a subset of properties","text":"<pre><code>from geff import GeffReader, construct\n\n\n# Open the geff file without reading any data into memory\ngeff_reader = GeffReader(path)\n\n# Print names of available node/edge properties\nprint(reader.node_prop_names, reader.edge_prop_names)\n# &gt;&gt;&gt; (['t', 'x', 'y', 'label', 'score'] ['color', 'score'])\n\ngeff_reader.read_node_props(['t', 'x', 'y'])\n# By default all edge properties will be loaded\ngeff_reader.read_edge_props()\n\n# Read the data of the geff into memory including only properties that have been loaded\nin_memory_geff = geff_reader.build()\n\n# Construct a graph representation of the data with the backend of your choice\ngraph = construct(**in_memory_geff, backend=\"networkx\")\n# Nodes will contain the attributes t, x, and y\n# Edges will contain the attributes color and score\n</code></pre>"},{"location":"tips-and-tricks/#filtering-based-on-nodes","title":"Filtering based on nodes","text":"<pre><code>from geff import GeffReader, construct\n\n\n# Open the geff file without reading any data into memory\ngeff_reader = GeffReader(path)\n# Load edge and node properties\ngeff_reader.read_node_props()\ngeff_reader.read_edge_props()\n# Access the property values, load it into memory as a numpy and then create the mask\nnode_mask = file_reader.node_props[\"t\"][\"values\"][:] &lt; 5\n\n# Read the data of the geff into memory using the mask to filter which nodes to load\nin_memory_geff = geff_reader.build(node_mask=node_mask)\n\n# Construct a graph representation of the data with the backend of your choice\ngraph = construct(**in_memory_geff, backend=\"networkx\")\n</code></pre>"},{"location":"tips-and-tricks/#filtering-based-on-edges","title":"Filtering based on edges","text":"<p>Note</p> <p>When loading a GEFF using an edge mask, by default all nodes will be loaded even if they are not contained within an unmasked edge. However <code>GeffReader.build</code> can take both a node and edge mask if constructed by the user.</p> <pre><code>from geff import GeffReader, construct\n\n\n# Open the geff file without reading any data into memory\ngeff_reader = GeffReader(path)\n# Load edge and node properties\ngeff_reader.read_node_props()\ngeff_reader.read_edge_props()\n# Access the property values, load it into memory as a numpy and then create the mask\nedge_mask = file_reader.edge_props[\"score\"][\"values\"][:] &lt; 0.5\n\n# Read the data of the geff into memory using the mask to filter which edges to load\nin_memory_geff = geff_reader.build(edge_mask=edge_mask)\n\n# Construct a graph representation of the data with the backend of your choice\ngraph = construct(**in_memory_geff, backend=\"networkx\")\n</code></pre>"},{"location":"tracking/","title":"Tracking graph standards","text":"<p>While GEFFs can store any graphs, many of our core users are concerned with tracking cells in microscopy imagery. Therefore, we provide special support and standardization for exchanging tracking GEFFs, or GEFFs that contain tracking outputs.</p>"},{"location":"tracking/#tracklet-and-lineage-id-properties","title":"Tracklet and lineage ID properties","text":"<p>Often when analyzing and visualizing tracking outputs, we assign IDs based on identity over time. The geff specification supports specifying and validating optional node properties representing tracklet and lineage IDs.</p> <ul> <li>Tracklet: A simple path of connected nodes where the initiating node has any incoming degree and outgoing degree at most 1 and the terminating node has incoming degree at most 1 and any outgoing degree, and other nodes along the path have in/out degree of 1. Each tracklet must contain the maximal set of connected nodes that match this definition - no sub-tracklets.</li> <li>Lineage: a weakly connected component of the graph</li> </ul> <p>The <code>tracklet</code> and <code>lineage</code> properties specified in the <code>track_node_props</code> section of the specification point to node properties that contain tracklet IDs or lineage IDs - each node in a tracklet/lineage has the same ID, and all nodes not in the same tracklet/lineage have different IDs. </p> <p>By providing and enforcing a definition of tracklet and lineage, and ensuring tracklet and lineage IDs can be exchanged rather than requiring them to be recomputed, we can ensure consistency of downstream analyses on the tracks across different tools.</p>"},{"location":"what-is-geff/","title":"What is geff?","text":"<p><code>geff</code> is a graph exchange file format that seeks to fulfill the following needs:</p> <ul> <li>Provide a storage/exchange format for graphs and optional segmentation</li> <li>Provide a common API with reference implementations for use in other projects</li> </ul>"},{"location":"what-is-geff/#design-decisions-and-assumptions","title":"Design Decisions and Assumptions","text":"<ul> <li>Raw image data is not included in the <code>geff</code> spec. However, to keep nodes linked to segmentation labels, support for specifying the seg_id of each node in a standard way, along with the path to the segmentation, are included in the <code>spec</code>.</li> <li>Since <code>geff</code> is an exchange format, we do not provide support for searching or filtering.</li> <li>We do not provide support for editing or changing the graph on the fly.</li> <li>In order to support efficient reading/writing, we assume the graph can fit into memory.</li> </ul>"},{"location":"reference/geff/","title":"geff","text":""},{"location":"reference/geff/#geff","title":"geff","text":""},{"location":"reference/geff/#geff.GeffMetadata","title":"GeffMetadata","text":"<p>               Bases: <code>BaseModel</code></p> <p>Geff metadata schema to validate the attributes json file in a geff zarr</p> <p>Parameters:</p> Name Type Description Default <code>geff_version</code> <code>str</code> <p>Geff version string following semantic versioning (MAJOR.MINOR.PATCH), optionally with .devN and/or +local parts (e.g., 0.3.1.dev6+g61d5f18). If not provided, the version will be set to the current geff package version.</p> <code>'1.1'</code> <code>directed</code> <code>bool</code> <p>True if the graph is directed, otherwise False.</p> required <code>axes</code> <code>list[Axis] | None</code> <p>Optional list of <code>Axis</code> objects defining the axes of each node             in the graph. The axes list is modeled after the             OME-zarr             specifications and is used to identify spatio-temporal properties on the             graph nodes. If the same names are used in the axes metadata of the             related image or segmentation data, applications can use this information             to align graph node locations with image data.             The order of the axes in the list is meaningful. For one, any downstream             properties that are an array of values with one value per (spatial) axis             will be in the order of the axis list (filtering to only the spatial axes by             the <code>type</code> field if needed). Secondly, if associated image or segmentation             data does not have axes metadata, the order of the spatiotemporal axes is a             good default guess for aligning the graph and the image data, although there             is no way to denote the channel dimension in the graph spec. If you are             writing out a geff with an associated segmentation and/or image dataset, we             highly recommend providing the axis names for your segmentation/image using             the OME-zarr spec, including channel dimensions if needed.</p> <code>None</code> <code>node_props_metadata</code> <code>dict[str, PropMetadata]</code> <p>Metadata for node properties. The keys are the property identifiers, and the values are PropMetadata objects describing the properties.There must be one entry for each node property.</p> required <code>edge_props_metadata</code> <code>dict[str, PropMetadata]</code> <p>Metadata for edge properties. The keys are the property identifiers, and the values are PropMetadata objects describing the properties.There must be one entry for each edge property.</p> required <code>sphere</code> <code>str | None</code> <p>Name of the optional <code>sphere</code> property.</p> <p>A sphere is defined by</p> <ul> <li>a center point, already given by the <code>space</code> type properties</li> <li>a radius scalar, stored in this property</li> </ul> <code>None</code> <code>ellipsoid</code> <code>str | None</code> <p>Name of the <code>ellipsoid</code> property.</p> <p>An ellipsoid is assumed to be in the same coordinate system as the <code>space</code> type properties.</p> <p>It is defined by</p> <ul> <li>a center point \\(c\\), already given by the <code>space</code> type properties</li> <li>a covariance matrix \\(\\Sigma\\), symmetric and positive-definite, stored in this   property as a <code>2x2</code>/<code>3x3</code> array.</li> </ul> <p>To plot the ellipsoid:</p> <ul> <li>Compute the eigendecomposition of the covariance matrix \\(\\Sigma = Q \\Lambda Q^{\\top}\\)</li> <li>Sample points \\(z\\) on the unit sphere</li> <li>Transform the points to the ellipsoid by \\(x = c + Q \\Lambda^{(1/2)} z\\).</li> </ul> <code>None</code> <code>track_node_props</code> <code>dict[Literal['lineage', 'tracklet'], str] | None</code> <p>Node properties denoting tracklet and/or lineage IDs. A tracklet is defined as a simple path of connected nodes where the initiating node has any incoming degree and outgoing degree at most 1, and the terminating node has incoming degree at most 1 and any outgoing degree, and other nodes along the path have in/out degree of 1. Each tracklet must contain the maximal set of connected nodes that match this definition - no sub-tracklets. A lineage is defined as a weakly connected component on the graph. The dictionary can store one or both of 'tracklet' or 'lineage' keys.</p> <code>None</code> <code>related_objects</code> <code>list[RelatedObject] | None</code> <p>A list of dictionaries of related objects such as labels or images. Each dictionary must contain 'type', 'path', and optionally 'label_prop' properties. The 'type' represents the data type. 'labels' and 'image' should be used for label and image objects, respectively. Other types are also allowed, The 'path' should be relative to the geff zarr-attributes file. It is strongly recommended all related objects are stored as siblings of the geff group within the top-level zarr group. The 'label_prop' is only valid for type 'labels' and specifies the node property that will be used to identify the labels in the related object.</p> <code>None</code> <code>display_hints</code> <code>DisplayHint | None</code> <p>Metadata indicating how spatiotemporal axes are displayed by a viewer</p> <code>None</code> <code>extra</code> <code>dict[str, Any]</code> <p>The optional <code>extra</code> object is a free-form dictionary that can hold any additional, application-specific metadata that is not covered by the core geff schema. Users may place arbitrary keys and values inside <code>extra</code> without fear of clashing with future reserved fields. Although the core <code>geff</code> reader makes these attributes available, their meaning and use are left entirely to downstream applications.</p> <code>&lt;class 'dict'&gt;</code>"},{"location":"reference/geff/#geff.GeffMetadata.read","title":"read","text":"<pre><code>read(store: StoreLike) -&gt; GeffMetadata\n</code></pre> <p>Helper function to read GeffMetadata from a zarr geff group.</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>zarr store | Path | str</code> <p>The geff store to read the metadata from</p> required <p>Returns:</p> Name Type Description <code>GeffMetadata</code> <code>GeffMetadata</code> <p>The GeffMetadata object</p>"},{"location":"reference/geff/#geff.GeffMetadata.write","title":"write","text":"<pre><code>write(store: StoreLike) -&gt; None\n</code></pre> <p>Helper function to write GeffMetadata into the group of a zarr geff store. Maintains consistency by preserving ignored attributes with their original values.</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>zarr store | Path | str</code> <p>The geff store to write the metadata to</p> required"},{"location":"reference/geff/#geff.GeffReader","title":"GeffReader","text":"<pre><code>GeffReader(source: StoreLike, validate: bool = True)\n</code></pre> <p>File reader class that allows subset reading to an intermediate dict representation.</p> <p>The subsets can be a subset of node and edge properties, and a subset of nodes and edges.</p> <p>Example: <pre><code>&gt;&gt;&gt; from pathlib import Path\n... from geff.file_reader import FileReader\n\n&gt;&gt;&gt; path = Path(\"example/path\")\n... file_reader = FileReader(path)\n... file_reader.read_node_prop(\"seg_id\")\n... # in_memory_geff will only have the node property \"seg_id\"\n... in_memory_geff = file_reader.build()\n... in_memory_geff\n\n&gt;&gt;&gt; file_reader.read_node_prop(\"t\")\n... # Now graph dict will have two node properties: \"seg_id\" and \"t\"\n... in_memory_geff = file_reader.build()\n... in_memory_geff\n\n&gt;&gt;&gt; in_memory_geff = file_reader.build(file_reader.node_props[\"t\"][\"values\"][:] &lt; 5)\n... # Now in_memory_geff will only be a subset with nodes \"t\" &lt; 5\n... in_memory_geff\n</code></pre></p> <p>File reader class that allows subset reading to an intermediate dict representation.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | Path | store</code> <p>Either a str/path to the root of the geff zarr (where the .attrs contains the geff metadata), or a zarr store object</p> required <code>validate</code> <code>bool</code> <p>Flag indicating whether to perform validation on the geff file before loading into memory. If set to False and there are format issues, will likely fail with a cryptic error. Defaults to True.</p> <code>True</code>"},{"location":"reference/geff/#geff.GeffReader._load_prop_to_memory","title":"_load_prop_to_memory","text":"<pre><code>_load_prop_to_memory(\n    zarr_prop: ZarrPropDict,\n    mask: NDArray[bool_] | None,\n    prop_metadata: PropMetadata,\n) -&gt; PropDictNpArray\n</code></pre> <p>Load a zarr property dictionary into memory, including deserialization.</p> <p>Has option to only load a subset of the nodes or edges by providing a mask.</p> <p>Parameters:</p> Name Type Description Default <code>zarr_prop</code> <code>ZarrPropDict</code> <p>The zarr property dictionary to load and deserialize.</p> required <code>mask</code> <code>NDArray[bool_] | None</code> <p>A mask to use to only include a subset of the elements. Can be None, which loads all the elements to memory.</p> required <code>prop_metadata</code> <code>PropMetadata</code> <p>The metadata of the given property.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the property is varlength and no <code>data</code> array is provided.</p> <p>Returns:</p> Name Type Description <code>PropDictNpArray</code> <code>PropDictNpArray</code> <p>The property loaded into memory as \"values\" and \"missing\" arrays.</p>"},{"location":"reference/geff/#geff.GeffReader._read_prop","title":"_read_prop","text":"<pre><code>_read_prop(\n    name: str, prop_type: Literal[\"node\", \"edge\"]\n) -&gt; ZarrPropDict\n</code></pre> <p>Read a property into a zarr property dictionary</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the property to read</p> required <code>prop_type</code> <code>Literal['node', 'edge']</code> <p>Either <code>node</code> or <code>edge</code></p> required <p>Returns:</p> Name Type Description <code>ZarrPropDict</code> <code>ZarrPropDict</code> <p>A dictionary with \"values\" \"missing\" and optionally \"data\" arrays holding the zarr arrays for a property.</p>"},{"location":"reference/geff/#geff.GeffReader.build","title":"build","text":"<pre><code>build(\n    node_mask: NDArray[bool_] | None = None,\n    edge_mask: NDArray[bool_] | None = None,\n) -&gt; InMemoryGeff\n</code></pre> <p>Build an <code>InMemoryGeff</code> by loading the data from a GEFF zarr.</p> <p>A set of nodes and edges can be selected using <code>node_mask</code> and <code>edge_mask</code>.</p> <p>Parameters:</p> Name Type Description Default <code>node_mask</code> <code>np.ndarray of bool</code> <p>A boolean numpy array to mask build a graph of a subset of nodes, where <code>node_mask</code> is equal to True. It must be a 1D array of length number of nodes.</p> <code>None</code> <code>edge_mask</code> <code>np.ndarray of bool</code> <p>A boolean numpy array to mask build a graph of a subset of edge, where <code>edge_mask</code> is equal to True. It must be a 1D array of length number of edges.</p> <code>None</code> <p>Returns:     InMemoryGeff: A dictionary of in memory numpy arrays representing the graph.</p>"},{"location":"reference/geff/#geff.GeffReader.read_edge_props","title":"read_edge_props","text":"<pre><code>read_edge_props(names: Iterable[str] | None = None) -&gt; None\n</code></pre> <p>Read the edge property with the name <code>name</code> from a GEFF.</p> <p>If no names are specified, then all properties will be loaded</p> <p>Call <code>build</code> to get the output <code>InMemoryGeff</code> with the loaded properties.</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>iterable of str</code> <p>The names of the edge properties to load. If None all node properties will be loaded.</p> <code>None</code>"},{"location":"reference/geff/#geff.GeffReader.read_node_props","title":"read_node_props","text":"<pre><code>read_node_props(names: Iterable[str] | None = None) -&gt; None\n</code></pre> <p>Read the node property with the name <code>name</code> from a GEFF.</p> <p>If no names are specified, then all properties will be loaded</p> <p>Call <code>build</code> to get the output <code>InMemoryGeff</code> with the loaded properties.</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>iterable of str</code> <p>The names of the node properties to load. If None all node properties will be loaded.</p> <code>None</code>"},{"location":"reference/geff/#geff.read","title":"read","text":"<pre><code>read(\n    store: StoreLike,\n    structure_validation: bool = ...,\n    node_props: list[str] | None = ...,\n    edge_props: list[str] | None = ...,\n    data_validation: ValidationConfig | None = ...,\n    *,\n    backend: Literal[\"networkx\"] = \"networkx\",\n) -&gt; tuple[NxGraph, GeffMetadata]\n</code></pre><pre><code>read(\n    store: StoreLike,\n    structure_validation: bool = ...,\n    node_props: list[str] | None = ...,\n    edge_props: list[str] | None = ...,\n    data_validation: ValidationConfig | None = ...,\n    *,\n    backend: Literal[\"rustworkx\"],\n) -&gt; tuple[RxGraph, GeffMetadata]\n</code></pre><pre><code>read(\n    store: StoreLike,\n    structure_validation: bool = ...,\n    node_props: list[str] | None = ...,\n    edge_props: list[str] | None = ...,\n    data_validation: ValidationConfig | None = ...,\n    *,\n    backend: Literal[\"spatial-graph\"],\n    position_attr: str = \"position\",\n) -&gt; tuple[SgGraph, GeffMetadata]\n</code></pre> <pre><code>read(\n    store: StoreLike,\n    structure_validation: bool = True,\n    node_props: list[str] | None = None,\n    edge_props: list[str] | None = None,\n    data_validation: ValidationConfig | None = None,\n    *,\n    backend: SupportedBackend = \"networkx\",\n    **backend_kwargs: Any,\n) -&gt; tuple[SupportedGraphType, GeffMetadata]\n</code></pre> <p>Read a GEFF to a chosen backend.</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>StoreLike</code> <p>The path or zarr store to the root of the geff zarr, where the .attrs contains the geff  metadata.</p> required <code>structure_validation</code> <code>bool</code> <p>Flag indicating whether to perform validation on the geff file before loading into memory. If set to False and there are format issues, will likely fail with a cryptic error. Defaults to True.</p> <code>True</code> <code>node_props</code> <code>list of str</code> <p>The names of the node properties to load, if None all properties will be loaded, defaults to None.</p> <code>None</code> <code>edge_props</code> <code>list of str</code> <p>The names of the edge properties to load, if None all properties will be loaded, defaults to None.</p> <code>None</code> <code>backend</code> <code>{'networkx', 'rustworkx', 'spatial-graph'}</code> <p>Flag for the chosen backend, default is \"networkx\".</p> <code>'networkx'</code> <code>data_validation</code> <code>ValidationConfig</code> <p>Optional configuration for which optional types of data to validate. Each option defaults to False.</p> <code>None</code> <code>backend_kwargs</code> <code>Any</code> <p>Additional kwargs that may be accepted by the backend when reading the data.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[SupportedGraphType, GeffMetadata]</code> <p>tuple[Any, GeffMetadata]: Graph object of the chosen backend, and the GEFF metadata.</p>"},{"location":"reference/geff/#geff.validate_structure","title":"validate_structure","text":"<pre><code>validate_structure(store: StoreLike) -&gt; None\n</code></pre> <p>Ensure that the structure of the zarr conforms to geff specification</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>str | Path | zarr store</code> <p>Check the geff zarr, either str/Path/store</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If geff specs are violated</p> <code>FileNotFoundError</code> <p>If store is not a valid zarr store or path doesn't exist</p>"},{"location":"reference/geff/#geff.write","title":"write","text":"<pre><code>write(\n    graph: RxGraph,\n    store: StoreLike,\n    metadata: GeffMetadata | None = ...,\n    axis_names: list[str] | None = ...,\n    axis_units: list[str | None] | None = ...,\n    axis_types: list[AxisType | None] | None = ...,\n    axis_scales: list[float | None] | None = ...,\n    scaled_units: list[str | None] | None = ...,\n    axis_offset: list[float | None] | None = ...,\n    zarr_format: Literal[2, 3] = ...,\n    structure_validation: bool = True,\n    overwrite: bool = False,\n    node_id_dict: dict[int, int] | None = ...,\n) -&gt; None\n</code></pre><pre><code>write(\n    graph: SupportedGraphType,\n    store: StoreLike,\n    metadata: GeffMetadata | None = ...,\n    axis_names: list[str] | None = ...,\n    axis_units: list[str | None] | None = ...,\n    axis_types: list[AxisType | None] | None = ...,\n    axis_scales: list[float | None] | None = ...,\n    scaled_units: list[str | None] | None = ...,\n    axis_offset: list[float | None] | None = ...,\n    zarr_format: Literal[2, 3] = ...,\n    structure_validation: bool = True,\n    overwrite: bool = False,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; None\n</code></pre> <pre><code>write(\n    graph: SupportedGraphType,\n    store: StoreLike,\n    metadata: GeffMetadata | None = None,\n    axis_names: list[str] | None = None,\n    axis_units: list[str | None] | None = None,\n    axis_types: list[AxisType | None] | None = None,\n    axis_scales: list[float | None] | None = None,\n    scaled_units: list[str | None] | None = None,\n    axis_offset: list[float | None] | None = None,\n    zarr_format: Literal[2, 3] = 2,\n    structure_validation: bool = True,\n    overwrite: bool = False,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; None\n</code></pre> <p>Write a supported graph object to the geff file format.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>SupportedGraphType</code> <p>An instance of a supported graph object.</p> required <code>store</code> <code>str | Path | zarr store</code> <p>The path/str to the output zarr, or the store itself. Opens in append mode, so will only overwrite geff-controlled groups.</p> required <code>metadata</code> <code>GeffMetadata</code> <p>The original metadata of the graph. Defaults to None. If provided, will override the graph properties.</p> <code>None</code> <code>axis_names</code> <code>list[str]</code> <p>The names of the spatial dims represented in position property. Defaults to None. Will override both value in graph properties and metadata if provided.</p> <code>None</code> <code>axis_units</code> <code>list[str | None]</code> <p>The units of the spatial dims represented in position property. Defaults to None. Will override value both value in graph properties and metadata if provided.</p> <code>None</code> <code>axis_types</code> <code>list[Literal[AxisType] | None]</code> <p>The types of the spatial dims represented in position property. Usually one of \"time\", \"space\", or \"channel\". Defaults to None. Will override both value in graph properties and metadata if provided.</p> <code>None</code> <code>axis_scales</code> <code>list[float | None] | None</code> <p>The scale to apply to the spatial dims. Defaults to None.</p> <code>None</code> <code>scaled_units</code> <code>list[str | None] | None</code> <p>The units of the spatial dims after scaling. Defaults to None.</p> <code>None</code> <code>axis_offset</code> <code>list[float | None] | None</code> <p>Amount to offset an axis after applying scaling factor. Defaults to None.</p> <code>None</code> <code>zarr_format</code> <code>Literal[2, 3]</code> <p>The version of zarr to write. Defaults to 2.</p> <code>2</code> <code>structure_validation</code> <code>bool</code> <p>If True, runs structural validation and does not write a geff that is invalid. Defaults to True.</p> <code>True</code> <code>overwrite</code> <code>bool</code> <p>If True, deletes any existing geff and writes a new geff. Defaults to False.</p> <code>False</code> <code>*args</code> <code>Any</code> <p>Additional args that may be accepted by the backend when writing from a specific type of graph.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Additional kwargs that may be accepted by the backend when writing from a specific type of graph.</p> <code>{}</code>"},{"location":"reference/geff/convert/","title":"convert","text":""},{"location":"reference/geff/convert/#geff.convert","title":"geff.convert","text":""},{"location":"reference/geff/convert/#geff.convert.ctc_tiffs_to_zarr","title":"ctc_tiffs_to_zarr","text":"<pre><code>ctc_tiffs_to_zarr(\n    ctc_path: Path,\n    output_store: StoreLike,\n    ctzyx: bool = False,\n    overwrite: bool = False,\n    zarr_format: Literal[2, 3] = 2,\n) -&gt; None\n</code></pre> <p>Convert a CTC file to a Zarr file.</p> <p>Parameters:</p> Name Type Description Default <code>ctc_path</code> <code>Path</code> <p>The path to the CTC file.</p> required <code>output_store</code> <code>StoreLike</code> <p>The path to the Zarr file.</p> required <code>ctzyx</code> <code>(optional, bool)</code> <p>Expand data to make it (T, C, Z, Y, X) otherwise it's (T,) + Frame shape. Defaults to False.</p> <code>False</code> <code>overwrite</code> <code>(optional, bool)</code> <p>Whether to overwrite the Zarr file if it already exists. Defaults to False.</p> <code>False</code> <code>zarr_format</code> <code>(optional, Literal[2, 3])</code> <p>The zarr specification to use when writing the zarr. Defaults to 2.</p> <code>2</code>"},{"location":"reference/geff/convert/#geff.convert.from_ctc_to_geff","title":"from_ctc_to_geff","text":"<pre><code>from_ctc_to_geff(\n    ctc_path: Path,\n    geff_path: Path,\n    segmentation_store: StoreLike | None = None,\n    tczyx: bool = False,\n    overwrite: bool = False,\n    zarr_format: Literal[2, 3] = 2,\n) -&gt; None\n</code></pre> <p>Convert a CTC file to a GEFF file.</p> <p>Parameters:</p> Name Type Description Default <code>ctc_path</code> <code>Path</code> <p>The path to the CTC file.</p> required <code>geff_path</code> <code>Path</code> <p>The path to the GEFF file.</p> required <code>segmentation_store</code> <code>StoreLike | None</code> <p>The path or store to save the segmentation to.                 If not provided, it won't be exported.</p> <code>None</code> <code>tczyx</code> <code>bool</code> <p>Expand data to make it (T, C, Z, Y, X) otherwise it's (T,) + Frame shape.</p> <code>False</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the GEFF file if it already exists.</p> <code>False</code> <code>zarr_format</code> <code>Literal[2, 3]</code> <p>The zarr specification to use when writing the zarr. Defaults to 2.</p> <code>2</code>"},{"location":"reference/geff/convert/#geff.convert.from_trackmate_xml_to_geff","title":"from_trackmate_xml_to_geff","text":"<pre><code>from_trackmate_xml_to_geff(\n    xml_path: Path | str,\n    geff_path: Path | str,\n    discard_filtered_spots: bool = False,\n    discard_filtered_tracks: bool = False,\n    overwrite: bool = False,\n    zarr_format: Literal[2, 3] = 2,\n) -&gt; None\n</code></pre> <p>Convert a TrackMate XML file to a GEFF file.</p> <p>Parameters:</p> Name Type Description Default <code>xml_path</code> <code>Path | str</code> <p>The path to the TrackMate XML file.</p> required <code>geff_path</code> <code>Store</code> <p>The path to the GEFF file.</p> required <code>discard_filtered_spots</code> <code>bool</code> <p>True to discard the spots filtered out in TrackMate, False otherwise. False by default.</p> <code>False</code> <code>discard_filtered_tracks</code> <code>bool</code> <p>True to discard the tracks filtered out in TrackMate, False otherwise. False by default.</p> <code>False</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the GEFF file if it already exists.</p> <code>False</code> <code>zarr_format</code> <code>Literal[2, 3]</code> <p>The version of zarr to write. Defaults to 2.</p> <code>2</code> <p>Raises:</p> Type Description <code>UserWarning</code> <p>If the XML file does not contain specific metadata tags or if there are issues with the TrackMate metadata.</p>"},{"location":"reference/geff/core_io/","title":"core_io","text":""},{"location":"reference/geff/core_io/#geff.core_io","title":"geff.core_io","text":""},{"location":"reference/geff/core_io/#geff.core_io.check_for_geff","title":"check_for_geff","text":"<pre><code>check_for_geff(\n    store: StoreLike, zarr_format: Literal[2, 3] = 2\n) -&gt; bool\n</code></pre> <p>Check a StoreLike for an existing geff and return True if already present</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>StoreLike</code> <p>StoreLike to check for a geff</p> required <code>zarr_format</code> <code>Literal[2, 3]</code> <p>Defaults to 2.</p> <code>2</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if a geff already exists</p>"},{"location":"reference/geff/core_io/#geff.core_io.construct_var_len_props","title":"construct_var_len_props","text":"<pre><code>construct_var_len_props(\n    arr_seq: Sequence[ArrayLike | None],\n) -&gt; PropDictNpArray\n</code></pre> <p>Converts a sequence of array like and None objects into a geff._typing.PropDictNpArray</p> <p>Creates a missing array with the indices of the None objects. Converts each element of the sequence into a numpy array. Prepends dummy dimensions to each element to ensure all elements have the same number of dimensions. Casts all arrays into a common dtype (if there is one). Turns the sequence into a numpy array with dtype object.</p> <p>Parameters:</p> Name Type Description Default <code>arr_seq</code> <code>Sequence[ArrayLike | None]</code> <p>A sequence of properties, with one entry per node or edge. Missing values are indicated by None entries.</p> required <p>Returns:</p> Name Type Description <code>PropDictNpArray</code> <code>PropDictNpArray</code> <p>A standardized version of the input properties where all entries are numpy arrays contained in an object array.</p>"},{"location":"reference/geff/core_io/#geff.core_io.delete_geff","title":"delete_geff","text":"<pre><code>delete_geff(\n    store: StoreLike, zarr_format: Literal[2, 3] = 2\n) -&gt; None\n</code></pre> <p>Delete a geff after writing</p> <p>Tries to handle multiple StoreLike inputs and avoids deleting non-geff contents in the store</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>StoreLike</code> <p>StoreLike geff that should be deleted</p> required <code>zarr_format</code> <code>Literal[2, 3]</code> <p>Zarr format used to write input store. Defaults to 2.</p> <code>2</code>"},{"location":"reference/geff/core_io/#geff.core_io.read_to_memory","title":"read_to_memory","text":"<pre><code>read_to_memory(\n    source: StoreLike,\n    structure_validation: bool = True,\n    node_props: Iterable[str] | None = None,\n    edge_props: Iterable[str] | None = None,\n    data_validation: ValidationConfig | None = None,\n) -&gt; InMemoryGeff\n</code></pre> <p>Read a GEFF zarr file to into memory as a series of numpy arrays in a dictionary.</p> <p>A subset of node and edge properties can be selected with the <code>node_props</code> and <code>edge_props</code> argument.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str | Path | zarr store</code> <p>Either a path to the root of the geff zarr (where the .attrs contains the geff metadata), or a zarr store object</p> required <code>structure_validation</code> <code>bool</code> <p>Flag indicating whether to perform metadata/structure validation on the geff file before loading into memory. If set to False and there are format issues, will likely fail with a cryptic error. Defaults to True.</p> <code>True</code> <code>data_validation</code> <code>ValidationConfig</code> <p>Optional configuration for which optional types of data to validate. Each option defaults to False.</p> <code>None</code> <code>node_props</code> <code>iterable of str</code> <p>The names of the node properties to load, if None all properties will be loaded, defaults to None.</p> <code>None</code> <code>edge_props</code> <code>iterable of str</code> <p>The names of the edge properties to load, if None all properties will be loaded, defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>InMemoryGeff</code> <p>A InMemoryGeff object containing the graph as a TypeDict of in memory numpy arrays</p> <code>InMemoryGeff</code> <p>(metadata, node_ids, edge_ids, node_props, edge_props)</p>"},{"location":"reference/geff/core_io/#geff.core_io.write_arrays","title":"write_arrays","text":"<pre><code>write_arrays(\n    geff_store: StoreLike,\n    node_ids: ndarray,\n    node_props: dict[str, PropDictNpArray] | None,\n    edge_ids: ndarray,\n    edge_props: dict[str, PropDictNpArray] | None,\n    metadata: GeffMetadata,\n    node_props_unsquish: dict[str, list[str]] | None = None,\n    edge_props_unsquish: dict[str, list[str]] | None = None,\n    zarr_format: Literal[2, 3] = 2,\n    structure_validation: bool = True,\n    overwrite: bool = False,\n) -&gt; None\n</code></pre> <p>Write a geff file from already constructed arrays of node and edge ids and props</p> <p>Currently does not do any validation that the arrays are valid, but could be added as an optional flag. Adds the PropMetadata for the nodes and edges, if not provided.</p> <p>Parameters:</p> Name Type Description Default <code>geff_store</code> <code>str | Path | zarr store</code> <p>The path/str to the geff zarr, or the store itself. Opens in append mode, so will only overwrite geff-controlled groups.</p> required <code>node_ids</code> <code>ndarray</code> <p>An array containing the node ids. Must have same dtype as edge_ids.</p> required <code>node_props</code> <code>dict[str, PropDictNpArray] | None</code> <p>A dictionary from node property names to (values, missing) arrays, which should have same length as node_ids.</p> required <code>edge_ids</code> <code>ndarray</code> <p>An array containing the edge ids. Must have same dtype as node_ids.</p> required <code>edge_props</code> <code>dict[str, PropDictNpArray] | None</code> <p>A dictionary from edge property names to (values, missing) arrays, which should have same length as edge_ids.</p> required <code>metadata</code> <code>GeffMetadata</code> <p>The metadata of the graph.</p> required <code>zarr_format</code> <code>Literal[2, 3]</code> <p>The zarr specification to use when writing the zarr. Defaults to 2.</p> <code>2</code> <code>node_props_unsquish</code> <code>dict[str, list[str]] | None</code> <p>a dictionary indicication how to \"unsquish\" a property into individual scalars (e.g.: <code>{\"pos\": [\"z\", \"y\", \"x\"]}</code> will store the position property as three individual properties called \"z\", \"y\", and \"x\".</p> <code>None</code> <code>edge_props_unsquish</code> <code>dict[str, list[str]] | None</code> <p>a dictionary indicication how to \"unsquish\" a property into individual scalars (e.g.: <code>{\"pos\": [\"z\", \"y\", \"x\"]}</code> will store the position property as three individual properties called \"z\", \"y\", and \"x\".</p> <code>None</code> <code>structure_validation</code> <code>bool</code> <p>If True, runs structural validation and does not write a geff that is invalid. Defaults to True.</p> <code>True</code> <code>overwrite</code> <code>bool</code> <p>If True, deletes any existing geff and writes a new geff. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>FileExistsError</code> <p>If a geff already exists in <code>geff_store</code></p>"},{"location":"reference/geff/core_io/#geff.core_io.write_dicts","title":"write_dicts","text":"<pre><code>write_dicts(\n    geff_store: StoreLike,\n    node_data: Iterable[tuple[Any, dict[str, Any]]],\n    edge_data: Iterable[tuple[Any, dict[str, Any]]],\n    node_prop_names: Sequence[str],\n    edge_prop_names: Sequence[str],\n    metadata: GeffMetadata,\n    zarr_format: Literal[2, 3] = 2,\n    structure_validation: bool = True,\n) -&gt; None\n</code></pre> <p>Write a dict-like graph representation to geff</p> <p>Parameters:</p> Name Type Description Default <code>geff_store</code> <code>str | Path | zarr store</code> <p>The path/str to the geff zarr, or the store itself. Opens in append mode, so will only overwrite geff-controlled groups.</p> required <code>node_data</code> <code>Sequence[tuple[Any, dict[str, Any]]]</code> <p>A sequence of tuples with node_ids and node_data, where node_data is a dictionary from str names to any values.</p> required <code>edge_data</code> <code>Sequence[tuple[Any, dict[str, Any]]]</code> <p>A sequence of tuples with edge_ids and edge_data, where edge_data is a dictionary from str names to any values.</p> required <code>node_prop_names</code> <code>Sequence[str]</code> <p>A list of node properties to include in the geff</p> required <code>edge_prop_names</code> <code>Sequence[str]</code> <p>A list of edge properties to include in the geff</p> required <code>metadata</code> <code>GeffMetadata</code> <p>The core metadata to write. Node/edge properties and axis min and maxes will be overwritten.</p> required <code>zarr_format</code> <code>Literal[2, 3]</code> <p>The zarr specification to use when writing the zarr. Defaults to 2.</p> <code>2</code> <code>structure_validation</code> <code>bool</code> <p>If True, runs structural validation and does not write a geff that is invalid. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the position prop is given and is not present on all nodes.</p>"},{"location":"reference/geff/testing/","title":"testing","text":""},{"location":"reference/geff/testing/#geff.testing","title":"geff.testing","text":""},{"location":"reference/geff/testing/data/","title":"data","text":""},{"location":"reference/geff/testing/data/#geff.testing.data","title":"geff.testing.data","text":"<p>Test data generation utilities for geff graphs.</p> <p>This module provides functions to create mock geff graphs for testing and development. It includes both simple convenience functions and a comprehensive function for advanced use cases.</p> <p>Examples:</p>"},{"location":"reference/geff/testing/data/#geff.testing.data--simple-2d-graph-with-defaults","title":"Simple 2D graph with defaults","text":"<pre><code>&gt;&gt;&gt; store, memory_geff = create_simple_2d_geff()\n&gt;&gt;&gt; # Creates: 10 nodes, 15 edges, undirected, 2D (x, y, t)\n</code></pre>"},{"location":"reference/geff/testing/data/#geff.testing.data--simple-3d-graph-with-custom-size","title":"Simple 3D graph with custom size","text":"<pre><code>&gt;&gt;&gt; store, memory_geff = create_simple_3d_geff(num_nodes=20, num_edges=30)\n&gt;&gt;&gt; # Creates: 20 nodes, 30 edges, undirected, 3D (x, y, z, t)\n</code></pre>"},{"location":"reference/geff/testing/data/#geff.testing.data--advanced-usage-with-full-control","title":"Advanced usage with full control","text":"<pre><code>&gt;&gt;&gt; store, memory_geff = create_mock_geff(\n...     node_id_dtype=\"int\",\n...     node_axis_dtypes={\"position\": \"float64\", \"time\": \"float32\"},\n...     directed=True,\n...     num_nodes=5,\n...     num_edges=8,\n...     extra_node_props={\"label\": \"str\", \"confidence\": \"float64\"},\n...     extra_edge_props={\"score\": \"float64\", \"color\": \"uint8\",\n...           \"weight\": \"float64\", \"type\": \"str\"},\n...     include_t=True,\n...     include_z=False,  # 2D only\n...     include_y=True,\n...     include_x=True,\n... )\n</code></pre>"},{"location":"reference/geff/testing/data/#geff.testing.data--advanced-usage-with-custom-arrays","title":"Advanced usage with custom arrays","text":"<pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; custom_labels = np.array([\"A\", \"B\", \"C\", \"D\", \"E\"])\n&gt;&gt;&gt; custom_scores = np.array([0.1, 0.5, 0.8, 0.3, 0.9])\n&gt;&gt;&gt; custom_edge_weights = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8])\n&gt;&gt;&gt; store, memory_geff = create_mock_geff(\n...     node_id_dtype=\"int\",\n...     node_axis_dtypes={\"position\": \"float64\", \"time\": \"float64\"},\n...     directed=False,\n...     num_nodes=5,\n...     num_edges=8,\n...     extra_node_props={\"label\": custom_labels, \"score\": custom_scores,\n...         \"confidence\": \"float64\"},\n...     extra_edge_props={\"weight\": custom_edge_weights, \"type\": \"str\"},\n...     include_t=True,\n...     include_z=False,\n...     include_y=True,\n...     include_x=True,\n... )\n</code></pre>"},{"location":"reference/geff/testing/data/#geff.testing.data--to-construct-an-graph-with-a-backend-graph-lib","title":"To construct an graph with a backend graph lib","text":"<pre><code>&gt;&gt;&gt; # Import construct function of your choice\n&gt;&gt;&gt; store, memory_geff = create_simple_2d_geff()\n&gt;&gt;&gt; graph = construct_nx(**memory_geff)\n&gt;&gt;&gt; # graph is a networkx Graph ready for analysis\n</code></pre>"},{"location":"reference/geff/testing/data/#geff.testing.data.ExampleNodeAxisPropsDtypes","title":"ExampleNodeAxisPropsDtypes","text":"<p>               Bases: <code>TypedDict</code></p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>ForwardRef('DTypeStr', module='geff.testing.data')</code> required <code>time</code> <code>ForwardRef('DTypeStr', module='geff.testing.data')</code> required"},{"location":"reference/geff/testing/data/#geff.testing.data.create_dummy_in_mem_geff","title":"create_dummy_in_mem_geff","text":"<pre><code>create_dummy_in_mem_geff(\n    node_id_dtype: NodeIdDTypeStr,\n    node_axis_dtypes: ExampleNodeAxisPropsDtypes,\n    directed: bool,\n    num_nodes: int = 5,\n    num_edges: int = 4,\n    extra_node_props: Mapping[str, DTypeStr | NDArray[Any]]\n    | None = None,\n    extra_edge_props: Mapping[str, DTypeStr | NDArray[Any]]\n    | None = None,\n    include_t: bool = True,\n    include_z: bool = True,\n    include_y: bool = True,\n    include_x: bool = True,\n    include_varlength: bool = False,\n    include_missing: bool = False,\n) -&gt; InMemoryGeff\n</code></pre> <p>Create dummy graph properties for testing.</p> <p>Parameters:</p> Name Type Description Default <code>node_id_dtype</code> <code>NodeIdDTypeStr</code> <p>Data type for node IDs</p> required <code>node_axis_dtypes</code> <code>ExampleNodeAxisPropsDtypes</code> <p>Dictionary specifying dtypes for node axis properties (space and time)</p> required <code>directed</code> <code>bool</code> <p>Whether the graph is directed</p> required <code>num_nodes</code> <code>int</code> <p>Number of nodes to generate</p> <code>5</code> <code>num_edges</code> <code>int</code> <p>Number of edges to generate</p> <code>4</code> <code>extra_node_props</code> <code>Mapping[str, DTypeStr | NDArray[Any]] | None</code> <p>Dict mapping property names to dtypes for extra node properties</p> <code>None</code> <code>extra_edge_props</code> <code>Mapping[str, DTypeStr | NDArray[Any]] | None</code> <p>Dict mapping property names to dtypes for extra edge properties</p> <code>None</code> <code>include_t</code> <code>bool</code> <p>Whether to include time dimension</p> <code>True</code> <code>include_z</code> <code>bool</code> <p>Whether to include z dimension</p> <code>True</code> <code>include_y</code> <code>bool</code> <p>Whether to include y dimension</p> <code>True</code> <code>include_x</code> <code>bool</code> <p>Whether to include x dimension</p> <code>True</code> <code>include_varlength</code> <code>bool</code> <p>Whether to include a variable length property. If true, will make a property on nodes called \"var_length\" that has 2d np arrays of various shapes</p> <code>False</code> <code>include_missing</code> <code>bool</code> <p>If true, creades a node and edge prop called \"sparse_prop\" where every other node/edge has a missing value</p> <code>False</code> <p>Returns:</p> Type Description <code>InMemoryGeff</code> <p>InMemoryGeff containing all graph properties</p>"},{"location":"reference/geff/testing/data/#geff.testing.data.create_empty_geff","title":"create_empty_geff","text":"<pre><code>create_empty_geff(\n    directed: bool = False,\n) -&gt; tuple[zarr.storage.MemoryStore, InMemoryGeff]\n</code></pre> <p>Creates a geff without any nodes or edges</p> <p>Parameters:</p> Name Type Description Default <code>directed</code> <code>bool</code> <p>Whether to create a directed graph. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[MemoryStore, InMemoryGeff]</code> <p>tuple[zarr.storage.MemoryStore, InMemoryGeff]</p>"},{"location":"reference/geff/testing/data/#geff.testing.data.create_mock_geff","title":"create_mock_geff","text":"<pre><code>create_mock_geff(\n    node_id_dtype: NodeIdDTypeStr,\n    node_axis_dtypes: ExampleNodeAxisPropsDtypes,\n    directed: bool,\n    num_nodes: int = 5,\n    num_edges: int = 4,\n    extra_node_props: Mapping[str, DTypeStr | NDArray[Any]]\n    | None = None,\n    extra_edge_props: Mapping[str, DTypeStr | NDArray[Any]]\n    | None = None,\n    include_t: bool = True,\n    include_z: bool = True,\n    include_y: bool = True,\n    include_x: bool = True,\n    include_varlength: bool = False,\n    include_missing: bool = False,\n) -&gt; tuple[zarr.storage.MemoryStore, InMemoryGeff]\n</code></pre> <p>Create a mock geff in memory and return the zarr store and the in memory geff.</p> <p>Parameters:</p> Name Type Description Default <code>node_id_dtype</code> <code>NodeIdDTypeStr</code> <p>Data type for node IDs</p> required <code>node_axis_dtypes</code> <code>ExampleNodeAxisPropsDtypes</code> <p>Dictionary specifying dtypes for node axis properties (space and time)</p> required <code>directed</code> <code>bool</code> <p>Whether the graph is directed</p> required <code>num_nodes</code> <code>int</code> <p>Number of nodes to generate</p> <code>5</code> <code>num_edges</code> <code>int</code> <p>Number of edges to generate</p> <code>4</code> <code>extra_node_props</code> <code>Mapping[str, DTypeStr | NDArray[Any]] | None</code> <p>Dict mapping property names to dtypes for extra node properties</p> <code>None</code> <code>extra_edge_props</code> <code>Mapping[str, DTypeStr | NDArray[Any]] | None</code> <p>Dict mapping property names to dtypes for extra edge properties</p> <code>None</code> <code>include_t</code> <code>bool</code> <p>Whether to include time dimension</p> <code>True</code> <code>include_z</code> <code>bool</code> <p>Whether to include z dimension</p> <code>True</code> <code>include_y</code> <code>bool</code> <p>Whether to include y dimension</p> <code>True</code> <code>include_x</code> <code>bool</code> <p>Whether to include x dimension</p> <code>True</code> <code>include_varlength</code> <code>bool</code> <p>Whether to include a variable length property. If true, will make a property on nodes called \"var_length\" that has 2d np arrays of various shapes</p> <code>False</code> <code>include_missing</code> <code>bool</code> <p>If true, creades a node prop called \"sparse_prop\" where every other node has a missing value</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[MemoryStore, InMemoryGeff]</code> <p>Tuple of (zarr store in memory, InMemoryGeff)</p>"},{"location":"reference/geff/testing/data/#geff.testing.data.create_simple_2d_geff","title":"create_simple_2d_geff","text":"<pre><code>create_simple_2d_geff(\n    num_nodes: int = 10,\n    num_edges: int = 15,\n    directed: bool = False,\n) -&gt; tuple[zarr.storage.MemoryStore, InMemoryGeff]\n</code></pre> <p>Create a simple 2D geff graph with default settings.</p> <p>This is a convenience function for creating basic 2D graphs without having to specify all the detailed parameters. Uses sensible defaults for common use cases.</p> <p>Parameters:</p> Name Type Description Default <code>num_nodes</code> <code>int</code> <p>Number of nodes to generate (default: 10)</p> <code>10</code> <code>num_edges</code> <code>int</code> <p>Number of edges to generate (default: 15)</p> <code>15</code> <code>directed</code> <code>bool</code> <p>Whether the graph is directed (default: False)</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[MemoryStore, InMemoryGeff]</code> <p>Tuple of (zarr store in memory, InMemoryGeff)</p>"},{"location":"reference/geff/testing/data/#geff.testing.data.create_simple_3d_geff","title":"create_simple_3d_geff","text":"<pre><code>create_simple_3d_geff(\n    num_nodes: int = 10,\n    num_edges: int = 15,\n    directed: bool = False,\n) -&gt; tuple[zarr.storage.MemoryStore, InMemoryGeff]\n</code></pre> <p>Create a simple 3D geff graph with default settings.</p> <p>This is a convenience function for creating basic 3D graphs without having to specify all the detailed parameters. Uses sensible defaults for common use cases.</p> <p>Parameters:</p> Name Type Description Default <code>num_nodes</code> <code>int</code> <p>Number of nodes to generate (default: 10)</p> <code>10</code> <code>num_edges</code> <code>int</code> <p>Number of edges to generate (default: 15)</p> <code>15</code> <code>directed</code> <code>bool</code> <p>Whether the graph is directed (default: False)</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[MemoryStore, InMemoryGeff]</code> <p>Tuple of (zarr store in memory, InMemoryGeff)</p>"},{"location":"reference/geff/testing/data/#geff.testing.data.create_simple_temporal_geff","title":"create_simple_temporal_geff","text":"<pre><code>create_simple_temporal_geff(\n    num_nodes: int = 10,\n    num_edges: int = 15,\n    directed: bool = False,\n) -&gt; tuple[zarr.storage.MemoryStore, InMemoryGeff]\n</code></pre> <p>Create a simple geff graph with only time dimension (no spatial dimensions).</p> <p>This function creates a graph with nodes, edges, and time coordinates, but no spatial dimensions (x, y, z). Useful for temporal-only analysis.</p> <p>Parameters:</p> Name Type Description Default <code>num_nodes</code> <code>int</code> <p>Number of nodes to generate (default: 10)</p> <code>10</code> <code>num_edges</code> <code>int</code> <p>Number of edges to generate (default: 15)</p> <code>15</code> <code>directed</code> <code>bool</code> <p>Whether the graph is directed (default: False)</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[MemoryStore, InMemoryGeff]</code> <p>Tuple of (zarr store in memory, InMemoryGeff)</p>"},{"location":"reference/geff/validate/","title":"validate","text":""},{"location":"reference/geff/validate/#geff.validate","title":"geff.validate","text":""},{"location":"reference/geff/validate/data/","title":"data","text":""},{"location":"reference/geff/validate/data/#geff.validate.data","title":"geff.validate.data","text":""},{"location":"reference/geff/validate/data/#geff.validate.data.ValidationConfig","title":"ValidationConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>bool</code> <code>False</code> <code>sphere</code> <code>bool</code> <code>False</code> <code>ellipsoid</code> <code>bool</code> <code>False</code> <code>lineage</code> <code>bool</code> <code>False</code> <code>tracklet</code> <code>bool</code> <code>False</code>"},{"location":"reference/geff/validate/data/#geff.validate.data.validate_data","title":"validate_data","text":"<pre><code>validate_data(\n    memory_geff: InMemoryGeff, config: ValidationConfig\n) -&gt; None\n</code></pre> <p>Validate the data of a geff based on the options selected in ValidationConfig</p> <p>Parameters:</p> Name Type Description Default <code>memory_geff</code> <code>InMemoryGeff</code> <p>An InMemoryGeff which contains metadata and dictionaries of node/edge property arrays</p> required <code>config</code> <code>ValidationConfig</code> <p>Configuration for which validation to run</p> required"},{"location":"reference/geff/validate/graph/","title":"graph","text":""},{"location":"reference/geff/validate/graph/#geff.validate.graph","title":"geff.validate.graph","text":""},{"location":"reference/geff/validate/graph/#geff.validate.graph.validate_no_repeated_edges","title":"validate_no_repeated_edges","text":"<pre><code>validate_no_repeated_edges(\n    edge_ids: ArrayLike,\n) -&gt; tuple[bool, np.ndarray]\n</code></pre> <p>Validates that there are no repeated edges in the array.</p> <p>Parameters:</p> Name Type Description Default <code>edge_ids</code> <code>ArrayLike</code> <p>2D array-like of edges with shape (M, 2). Each row is (source, target).</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[bool, ndarray]</code> <p>A tuple (is_valid, repeated_edges) where: - is_valid (bool): True if there are no repeated edges, False otherwise. - repeated_edges (np.ndarray): An array of duplicated edges. Empty if valid.</p>"},{"location":"reference/geff/validate/graph/#geff.validate.graph.validate_no_self_edges","title":"validate_no_self_edges","text":"<pre><code>validate_no_self_edges(\n    edge_ids: ArrayLike,\n) -&gt; tuple[bool, np.ndarray]\n</code></pre> <p>Validates that there are no self-edges in the provided array of edges.</p> <p>Parameters:</p> Name Type Description Default <code>edge_ids</code> <code>ArrayLike</code> <p>2D array-like of edges with shape (M, 2). Each row is (source, target).</p> required <p>Returns:</p> Type Description <code>tuple[bool, ndarray]</code> <p>tuple[bool, np.ndarray]: A tuple (is_valid, problematic_nodes) where: - is_valid (bool): True if no node has an edge to itself, False otherwise. - problematic_nodes (np.ndarray): Array of node IDs that have self-edges.   Empty if valid.</p>"},{"location":"reference/geff/validate/graph/#geff.validate.graph.validate_nodes_for_edges","title":"validate_nodes_for_edges","text":"<pre><code>validate_nodes_for_edges(\n    node_ids: ArrayLike, edge_ids: ArrayLike\n) -&gt; tuple[bool, np.ndarray]\n</code></pre> <p>Validates that all edges in <code>edge_ids</code> reference node IDs present in <code>node_ids</code>.</p> <p>This function checks whether each edge in <code>edge_ids</code> consists of node IDs that exist in <code>node_ids</code>. It returns a boolean indicating whether all edges are valid, and a list of invalid edges.</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>ArrayLike</code> <p>1D array-like of valid node IDs (integers).</p> required <code>edge_ids</code> <code>ArrayLike</code> <p>2D array-like of edges with shape (M, 2), where each row is (source, target).</p> required <p>Returns:</p> Type Description <code>tuple[bool, ndarray]</code> <p>tuple[bool, np.ndarray]: - all_edges_valid (bool): True if all edges reference valid node IDs. - invalid_edges (np.ndarray): Array of (source, target) pairs for   invalid edges.</p>"},{"location":"reference/geff/validate/graph/#geff.validate.graph.validate_unique_node_ids","title":"validate_unique_node_ids","text":"<pre><code>validate_unique_node_ids(\n    node_ids: ArrayLike,\n) -&gt; tuple[bool, np.ndarray]\n</code></pre> <p>Validates that all node ids are unique</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>ArrayLike</code> <p>1D arraylike of node ids</p> required <p>Returns:</p> Type Description <code>tuple[bool, ndarray]</code> <p>tuple[bool, np.ndarray]: - valid (bool): True if all node ids are unique - errors (list[ints]): List of any non-unique node ids</p>"},{"location":"reference/geff/validate/segmentation/","title":"segmentation","text":""},{"location":"reference/geff/validate/segmentation/#geff.validate.segmentation","title":"geff.validate.segmentation","text":""},{"location":"reference/geff/validate/segmentation/#geff.validate.segmentation.axes_match_seg_dims","title":"axes_match_seg_dims","text":"<pre><code>axes_match_seg_dims(\n    memory_geff: InMemoryGeff, segmentation: ArrayLike\n) -&gt; tuple[bool, list[str]]\n</code></pre> <p>Validate that geff axes metadata have the same number of dimensions as the segmentation data.</p> <p>Parameters:</p> Name Type Description Default <code>memory_geff</code> <code>InMemoryGeff</code> <p>An InMemoryGeff to validate</p> required <code>segmentation</code> <code>ArrayLike</code> <p>a 3D or 4D segmentation array (t, (z), y, x).</p> required <p>Returns:</p> Type Description <code>bool</code> <p>tuple (bool, list[str])</p> <code>list[str]</code> <p>True if all checks passed</p> <code>tuple[bool, list[str]]</code> <p>False if the store does not provide metadata or if the number of dimensions in the</p> <code>tuple[bool, list[str]]</code> <p>metadata does not match that of the segmentation.</p> <code>tuple[bool, list[str]]</code> <p>A list of length 0 or 1 with the encountered error, if any.</p>"},{"location":"reference/geff/validate/segmentation/#geff.validate.segmentation.graph_is_in_seg_bounds","title":"graph_is_in_seg_bounds","text":"<pre><code>graph_is_in_seg_bounds(\n    memory_geff: InMemoryGeff,\n    segmentation: ArrayLike,\n    scale: Sequence[float] | None = None,\n) -&gt; tuple[bool, list[str]]\n</code></pre> <p>Validate that geff axes metadata have the same number of dimensions as the segmentation data.</p> <p>Parameters:</p> Name Type Description Default <code>memory_geff</code> <code>InMemoryGeff</code> <p>An InMemoryGeff to validate</p> required <code>segmentation</code> <code>ArrayLike</code> <p>a 3D or 4D segmentation array (t, (z), y, x).</p> required <code>scale</code> <code>tuple[float] | list[float] | None = None</code> <p>optional scaling tuple, with the same length as the number of dimensions in the segmentation data.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>tuple (bool, list[str])</p> <code>list[str]</code> <p>True if all checks passed</p> <code>tuple[bool, list[str]]</code> <p>False if the store does not provide metadata, if the provided scale tuple does not have the same length as the number of dimensions in the segmentation, if the number of dimensions in the metadata does not match that of the segmentation, or if the (scaled) graph data is not within the segmentation bounds.</p> <code>tuple[bool, list[str]]</code> <p>A list of length 0 or 1 with the encountered error, if any.</p>"},{"location":"reference/geff/validate/segmentation/#geff.validate.segmentation.has_seg_ids_at_coords","title":"has_seg_ids_at_coords","text":"<pre><code>has_seg_ids_at_coords(\n    segmentation: ArrayLike,\n    coords: Sequence[Sequence[int]],\n    seg_ids: Sequence[int],\n    scale: Sequence[float] | None = None,\n) -&gt; tuple[bool, list[str]]\n</code></pre> <p>Validates that the pixels at given coordinates in the segmentation have a value equal   to the provided seg_ids.</p> <p>Parameters:</p> Name Type Description Default <code>segmentation</code> <code>ArrayLike</code> <p>a 3D or 4D segmentation array (t, (z), y, x).</p> required <code>coords</code> <code>Sequence[Sequence[int]]</code> <p>Sequence of t(z)yx coordinates, should have the same order as the segmentation dimensions.</p> required <code>seg_ids</code> <code>Sequence[int]</code> <p>Sequence of corresponding seg_ids to check.</p> required <code>scale</code> <code>Sequence[float] | None = None</code> <p>optional scaling tuple, with the same length as the number of dimensions in the segmentation data.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>tuple[bool, list[str]]:</p> <code>list[str]</code> <p>True if all checks pass, False if an error was encountered or if there is no</p> <code>tuple[bool, list[str]]</code> <p>match.</p> <code>tuple[bool, list[str]]</code> <p>A list of encountered errors (can be of length 1 when returning early).</p>"},{"location":"reference/geff/validate/segmentation/#geff.validate.segmentation.has_seg_ids_at_time_points","title":"has_seg_ids_at_time_points","text":"<pre><code>has_seg_ids_at_time_points(\n    segmentation: ArrayLike,\n    time_points: Sequence[int],\n    seg_ids: Sequence[int],\n    metadata: GeffMetadata | None = None,\n) -&gt; tuple[bool, list[str]]\n</code></pre> <p>Validates that labels with given seg_ids exist at time points t. If a store is provided, the time axis will be identified by the metadata using the 'type' key. If this is not possible, it is assumed that time is on axis 0.</p> <p>Parameters:</p> Name Type Description Default <code>segmentation</code> <code>ArrayLike</code> <p>a 3D or 4D segmentation array (t, (z), y, x).</p> required <code>time_points</code> <code>Sequence[int]</code> <p>Sequence of time points to check.</p> required <code>seg_ids</code> <code>Sequence[int]</code> <p>Sequence of seg_ids to check.</p> required <code>metadata</code> <code>GeffMetadata</code> <p>If provided, it will attempt to read the axis order from the metadata. Otherwise, it is assumed that the dimension order is t(z)yx.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>tuple (bool, list[str])</p> <code>list[str]</code> <p>True if all seg_ids are present at their respective time points, False if an</p> <code>tuple[bool, list[str]]</code> <p>Index error is encountered or if there are any missing labels.</p> <code>tuple[bool, list[str]]</code> <p>A list of encountered errors (can be of length 1 when returning early).</p>"},{"location":"reference/geff/validate/segmentation/#geff.validate.segmentation.has_valid_seg_id","title":"has_valid_seg_id","text":"<pre><code>has_valid_seg_id(\n    memory_geff: InMemoryGeff, seg_id: str = \"seg_id\"\n) -&gt; tuple[bool, list[str]]\n</code></pre> <p>Validate that all nodes in the geff have a property 'seg_id', that is of type integer.</p> <p>Parameters:</p> Name Type Description Default <code>memory_geff</code> <code>InMemoryGeff</code> <p>An InMemoryGeff to check for seg_id</p> required <code>seg_id</code> <code>str</code> <p>the key to the dataset storing the segmentation value.</p> <code>'seg_id'</code> <p>Returns:</p> Type Description <code>bool</code> <p>tuple (bool, list[str])</p> <code>list[str]</code> <p>True if the checks passed, False if validation failed due to missing data or</p> <code>tuple[bool, list[str]]</code> <p>non-integer seg_ids.</p> <code>tuple[bool, list[str]]</code> <p>A list of encountered errors.</p>"},{"location":"reference/geff/validate/shapes/","title":"shapes","text":""},{"location":"reference/geff/validate/shapes/#geff.validate.shapes","title":"geff.validate.shapes","text":""},{"location":"reference/geff/validate/shapes/#geff.validate.shapes.validate_ellipsoid","title":"validate_ellipsoid","text":"<pre><code>validate_ellipsoid(\n    covariance: ndarray, axes: list[Axis] | None\n) -&gt; None\n</code></pre> <p>Validate that ellipsoid data has a valid covariance matrix</p> <p>The first axis of the covariance array corresponds to the number of nodes. The remaining axes correspond to the number of spatial axes.</p> <p>Parameters:</p> Name Type Description Default <code>covariance</code> <code>ndarray</code> <p>Covariance array stored as values for an ellipsoid property</p> required <code>axes</code> <code>list[Axis]</code> <p>List of Axis metadata</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Must define space axes in order to have ellipsoid data</p> <code>ValueError</code> <p>Ellipsoid covariance matrix must have 1 + number of spatial dimensions</p> <code>ValueError</code> <p>Spatial dimensions of covariance matrix must be equal</p> <code>ValueError</code> <p>Ellipsoid covariance matrices must be symmetric</p> <code>ValueError</code> <p>Ellipsoid covariance matrices must be positive-definite</p>"},{"location":"reference/geff/validate/shapes/#geff.validate.shapes.validate_sphere","title":"validate_sphere","text":"<pre><code>validate_sphere(radius: ndarray) -&gt; None\n</code></pre> <p>Validate that sphere data has nonzero radii and is 1d</p> <p>Parameters:</p> Name Type Description Default <code>radius</code> <code>ndarray</code> <p>Values array of a sphere property</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>Sphere radius values must be non-negative</p> <code>ValueError</code> <p>Sphere radius values must be 1D</p>"},{"location":"reference/geff/validate/structure/","title":"structure","text":""},{"location":"reference/geff/validate/structure/#geff.validate.structure","title":"geff.validate.structure","text":""},{"location":"reference/geff/validate/structure/#geff.validate.structure._validate_axes_structure","title":"_validate_axes_structure","text":"<pre><code>_validate_axes_structure(\n    graph: Group, meta: GeffMetadata\n) -&gt; None\n</code></pre> <p>Verify that any metadata regarding axes is actually present in the data</p> <ul> <li>Property exists with name matching Axis name</li> <li>Data is 1D</li> <li>Missing values not allowed</li> </ul> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>Group</code> <p>The zarr group containing the geff metadata</p> required <code>meta</code> <code>GeffMetadata</code> <p>Metadata from geff</p> required"},{"location":"reference/geff/validate/structure/#geff.validate.structure._validate_edges_group","title":"_validate_edges_group","text":"<pre><code>_validate_edges_group(\n    edges_group: Group, metadata: GeffMetadata\n) -&gt; None\n</code></pre> <p>Validate the structure of an edges group in a GEFF zarr store.</p>"},{"location":"reference/geff/validate/structure/#geff.validate.structure._validate_nodes_group","title":"_validate_nodes_group","text":"<pre><code>_validate_nodes_group(\n    nodes_group: Group, metadata: GeffMetadata\n) -&gt; None\n</code></pre> <p>Validate the structure of a nodes group in a GEFF zarr store.</p>"},{"location":"reference/geff/validate/structure/#geff.validate.structure._validate_props_group","title":"_validate_props_group","text":"<pre><code>_validate_props_group(\n    props_group: Group,\n    expected_len: int,\n    parent_key: str,\n    props_metadata: dict[str, PropMetadata],\n) -&gt; None\n</code></pre> <p>Validate every property subgroup under <code>props_group</code>.</p>"},{"location":"reference/geff/validate/structure/#geff.validate.structure.validate_structure","title":"validate_structure","text":"<pre><code>validate_structure(store: StoreLike) -&gt; None\n</code></pre> <p>Ensure that the structure of the zarr conforms to geff specification</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>str | Path | zarr store</code> <p>Check the geff zarr, either str/Path/store</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If geff specs are violated</p> <code>FileNotFoundError</code> <p>If store is not a valid zarr store or path doesn't exist</p>"},{"location":"reference/geff/validate/tracks/","title":"tracks","text":""},{"location":"reference/geff/validate/tracks/#geff.validate.tracks","title":"geff.validate.tracks","text":""},{"location":"reference/geff/validate/tracks/#geff.validate.tracks.validate_lineages","title":"validate_lineages","text":"<pre><code>validate_lineages(\n    node_ids: ArrayLike,\n    edge_ids: ArrayLike,\n    lineage_ids: ArrayLike,\n) -&gt; tuple[bool, list[str]]\n</code></pre> <p>Validates if each lineage is a valid, isolated connected component.</p> <p>A lineage is considered valid if and only if the set of nodes belonging to it is identical to one of the graph's weakly connected components. This efficiently ensures both internal connectivity and external isolation.</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>ArrayLike</code> <p>A sequence of unique node identifiers in the graph.</p> required <code>edge_ids</code> <code>ArrayLike</code> <p>A sequence of (source, target) pairs representing directed edges.</p> required <code>lineage_ids</code> <code>ArrayLike</code> <p>A sequence of lineage identifiers corresponding to each node in <code>node_ids</code>.</p> required <p>Returns:</p> Type Description <code>tuple[bool, list[str]]</code> <p>A tuple containing: - is_valid (bool): True if all lineages are valid connected   components, False otherwise. - errors (list[str]): A list of error messages for each invalid   lineage.</p>"},{"location":"reference/geff/validate/tracks/#geff.validate.tracks.validate_tracklets","title":"validate_tracklets","text":"<pre><code>validate_tracklets(\n    node_ids: ArrayLike,\n    edge_ids: ArrayLike,\n    tracklet_ids: ArrayLike,\n) -&gt; tuple[bool, list[str]]\n</code></pre> <p>Validates if each tracklet forms a single, cycle-free path using NetworkX for improved performance.</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>ArrayLike</code> <p>Sequence of node identifiers.</p> required <code>edge_ids</code> <code>ArrayLike</code> <p>Sequence of edges as (source, target) node ID pairs. Edges must be between nodes in <code>node_ids</code>.</p> required <code>tracklet_ids</code> <code>ArrayLike</code> <p>Sequence of tracklet IDs corresponding to each node.</p> required <p>Returns:</p> Type Description <code>tuple[bool, list[str]]</code> <p>tuple[bool, list[str]]: - is_valid (bool): True if all tracklets are valid, otherwise False. - errors (list[str]): List of error messages for invalid tracklets.</p>"},{"location":"reference/geff_spec/","title":"geff_spec","text":""},{"location":"reference/geff_spec/#geff_spec","title":"geff_spec","text":""},{"location":"reference/geff_spec/#geff_spec.Axis","title":"Axis","text":"<p>               Bases: <code>BaseModel</code></p> <p>The axes list is modeled after the OME-zarr specifications and is used to identify spatio-temporal properties on the graph nodes.</p> <p>The <code>name</code> must be an existing attribute on the nodes. The optional <code>type</code> key must be one of <code>space</code>, <code>time</code> or <code>channel</code>, though readers may not use this information. An optional <code>unit</code> key should match the valid OME-Zarr units and <code>min</code> and <code>max</code> keys define the range of the axis</p> <p>The optional <code>scale</code> field can be used to store a scaling factor such as converting the data from pixel space into real world units. The associated, optional <code>scaled_unit</code> field specifies the output unit after applying <code>scale</code> to the data.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the corresponding node property</p> required <code>type</code> <code>Literal['space', 'time', 'channel'] | None</code> <p>The type of data encoded in this axis, one of ('space', 'time', 'channel') or None</p> <code>None</code> <code>unit</code> <code>str | Literal['angstrom', 'attometer', 'centimeter', 'decimeter', 'exameter', 'femtometer', 'foot', 'gigameter', 'hectometer', 'inch', 'kilometer', 'megameter', 'meter', 'micrometer', 'mile', 'millimeter', 'nanometer', 'parsec', 'petameter', 'picometer', 'terameter', 'yard', 'yoctometer', 'yottameter', 'zeptometer', 'zettameter', 'pixel'] | Literal['attosecond', 'centisecond', 'day', 'decisecond', 'exasecond', 'femtosecond', 'gigasecond', 'hectosecond', 'hour', 'kilosecond', 'megasecond', 'microsecond', 'millisecond', 'minute', 'nanosecond', 'petasecond', 'picosecond', 'second', 'terasecond', 'yoctosecond', 'yottasecond', 'zeptosecond', 'zettasecond', 'frame'] | None</code> <p>Optional, the unit for this axis. If the type is 'space' or 'time', we recommend utilizing the OME-NGFF spatial or temporal units respectively.</p> <code>None</code> <code>min</code> <code>float | None</code> <p>Optional, the minimum value for this axis.</p> <code>None</code> <code>max</code> <code>float | None</code> <p>Optional, the minimum value for this axis.</p> <code>None</code> <code>scale</code> <code>float | None</code> <p>Optional, a scaling factor that can be applied to the data</p> <code>None</code> <code>scaled_unit</code> <code>str | Literal['angstrom', 'attometer', 'centimeter', 'decimeter', 'exameter', 'femtometer', 'foot', 'gigameter', 'hectometer', 'inch', 'kilometer', 'megameter', 'meter', 'micrometer', 'mile', 'millimeter', 'nanometer', 'parsec', 'petameter', 'picometer', 'terameter', 'yard', 'yoctometer', 'yottameter', 'zeptometer', 'zettameter', 'pixel'] | Literal['attosecond', 'centisecond', 'day', 'decisecond', 'exasecond', 'femtosecond', 'gigasecond', 'hectosecond', 'hour', 'kilosecond', 'megasecond', 'microsecond', 'millisecond', 'minute', 'nanosecond', 'petasecond', 'picosecond', 'second', 'terasecond', 'yoctosecond', 'yottasecond', 'zeptosecond', 'zettasecond', 'frame'] | None</code> <p>Optional, the unit after applying the <code>scale</code> value to the data. If <code>scaled_unit</code> is set, a <code>scale</code> value must also be provided.</p> <code>None</code> <code>offset</code> <code>float | None</code> <p>Optional, the amount by which to offset this axis after applying the <code>scale</code> if specified.</p> <code>None</code>"},{"location":"reference/geff_spec/#geff_spec.DisplayHint","title":"DisplayHint","text":"<p>               Bases: <code>BaseModel</code></p> <p>Metadata indicating how spatiotemporal axes are displayed by a viewer</p> <p>Parameters:</p> Name Type Description Default <code>display_horizontal</code> <code>str</code> <p>Which spatial axis to use for horizontal display</p> required <code>display_vertical</code> <code>str</code> <p>Which spatial axis to use for vertical display</p> required <code>display_depth</code> <code>str | None</code> <p>Optional, which spatial axis to use for depth display</p> <code>None</code> <code>display_time</code> <code>str | None</code> <p>Optional, which temporal axis to use for time</p> <code>None</code>"},{"location":"reference/geff_spec/#geff_spec.GeffMetadata","title":"GeffMetadata","text":"<p>               Bases: <code>BaseModel</code></p> <p>Geff metadata schema to validate the attributes json file in a geff zarr</p> <p>Parameters:</p> Name Type Description Default <code>geff_version</code> <code>str</code> <p>Geff version string following semantic versioning (MAJOR.MINOR.PATCH), optionally with .devN and/or +local parts (e.g., 0.3.1.dev6+g61d5f18). If not provided, the version will be set to the current geff package version.</p> <code>'1.1'</code> <code>directed</code> <code>bool</code> <p>True if the graph is directed, otherwise False.</p> required <code>axes</code> <code>list[Axis] | None</code> <p>Optional list of <code>Axis</code> objects defining the axes of each node             in the graph. The axes list is modeled after the             OME-zarr             specifications and is used to identify spatio-temporal properties on the             graph nodes. If the same names are used in the axes metadata of the             related image or segmentation data, applications can use this information             to align graph node locations with image data.             The order of the axes in the list is meaningful. For one, any downstream             properties that are an array of values with one value per (spatial) axis             will be in the order of the axis list (filtering to only the spatial axes by             the <code>type</code> field if needed). Secondly, if associated image or segmentation             data does not have axes metadata, the order of the spatiotemporal axes is a             good default guess for aligning the graph and the image data, although there             is no way to denote the channel dimension in the graph spec. If you are             writing out a geff with an associated segmentation and/or image dataset, we             highly recommend providing the axis names for your segmentation/image using             the OME-zarr spec, including channel dimensions if needed.</p> <code>None</code> <code>node_props_metadata</code> <code>dict[str, PropMetadata]</code> <p>Metadata for node properties. The keys are the property identifiers, and the values are PropMetadata objects describing the properties.There must be one entry for each node property.</p> required <code>edge_props_metadata</code> <code>dict[str, PropMetadata]</code> <p>Metadata for edge properties. The keys are the property identifiers, and the values are PropMetadata objects describing the properties.There must be one entry for each edge property.</p> required <code>sphere</code> <code>str | None</code> <p>Name of the optional <code>sphere</code> property.</p> <p>A sphere is defined by</p> <ul> <li>a center point, already given by the <code>space</code> type properties</li> <li>a radius scalar, stored in this property</li> </ul> <code>None</code> <code>ellipsoid</code> <code>str | None</code> <p>Name of the <code>ellipsoid</code> property.</p> <p>An ellipsoid is assumed to be in the same coordinate system as the <code>space</code> type properties.</p> <p>It is defined by</p> <ul> <li>a center point \\(c\\), already given by the <code>space</code> type properties</li> <li>a covariance matrix \\(\\Sigma\\), symmetric and positive-definite, stored in this   property as a <code>2x2</code>/<code>3x3</code> array.</li> </ul> <p>To plot the ellipsoid:</p> <ul> <li>Compute the eigendecomposition of the covariance matrix \\(\\Sigma = Q \\Lambda Q^{\\top}\\)</li> <li>Sample points \\(z\\) on the unit sphere</li> <li>Transform the points to the ellipsoid by \\(x = c + Q \\Lambda^{(1/2)} z\\).</li> </ul> <code>None</code> <code>track_node_props</code> <code>dict[Literal['lineage', 'tracklet'], str] | None</code> <p>Node properties denoting tracklet and/or lineage IDs. A tracklet is defined as a simple path of connected nodes where the initiating node has any incoming degree and outgoing degree at most 1, and the terminating node has incoming degree at most 1 and any outgoing degree, and other nodes along the path have in/out degree of 1. Each tracklet must contain the maximal set of connected nodes that match this definition - no sub-tracklets. A lineage is defined as a weakly connected component on the graph. The dictionary can store one or both of 'tracklet' or 'lineage' keys.</p> <code>None</code> <code>related_objects</code> <code>list[RelatedObject] | None</code> <p>A list of dictionaries of related objects such as labels or images. Each dictionary must contain 'type', 'path', and optionally 'label_prop' properties. The 'type' represents the data type. 'labels' and 'image' should be used for label and image objects, respectively. Other types are also allowed, The 'path' should be relative to the geff zarr-attributes file. It is strongly recommended all related objects are stored as siblings of the geff group within the top-level zarr group. The 'label_prop' is only valid for type 'labels' and specifies the node property that will be used to identify the labels in the related object.</p> <code>None</code> <code>display_hints</code> <code>DisplayHint | None</code> <p>Metadata indicating how spatiotemporal axes are displayed by a viewer</p> <code>None</code> <code>extra</code> <code>dict[str, Any]</code> <p>The optional <code>extra</code> object is a free-form dictionary that can hold any additional, application-specific metadata that is not covered by the core geff schema. Users may place arbitrary keys and values inside <code>extra</code> without fear of clashing with future reserved fields. Although the core <code>geff</code> reader makes these attributes available, their meaning and use are left entirely to downstream applications.</p> <code>&lt;class 'dict'&gt;</code>"},{"location":"reference/geff_spec/#geff_spec.GeffMetadata.read","title":"read","text":"<pre><code>read(store: StoreLike) -&gt; GeffMetadata\n</code></pre> <p>Helper function to read GeffMetadata from a zarr geff group.</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>zarr store | Path | str</code> <p>The geff store to read the metadata from</p> required <p>Returns:</p> Name Type Description <code>GeffMetadata</code> <code>GeffMetadata</code> <p>The GeffMetadata object</p>"},{"location":"reference/geff_spec/#geff_spec.GeffMetadata.write","title":"write","text":"<pre><code>write(store: StoreLike) -&gt; None\n</code></pre> <p>Helper function to write GeffMetadata into the group of a zarr geff store. Maintains consistency by preserving ignored attributes with their original values.</p> <p>Parameters:</p> Name Type Description Default <code>store</code> <code>zarr store | Path | str</code> <p>The geff store to write the metadata to</p> required"},{"location":"reference/geff_spec/#geff_spec.GeffSchema","title":"GeffSchema","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters:</p> Name Type Description Default <code>geff</code> <code>GeffMetadata</code> <p>geff_metadata</p> required"},{"location":"reference/geff_spec/#geff_spec.PropMetadata","title":"PropMetadata","text":"<p>               Bases: <code>BaseModel</code></p> <p>Each property must have a string identifier (the group name for the property) and a dtype. The dtype can be any string that can be coerced into a numpy dtype, or the special <code>varlength</code> dtype indicating this is a variable length property (coming soon). String properties should have dtype <code>str</code>, not <code>varlength</code>, even though they are stored using the same variable length mechanism.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str</code> <p>Identifier of the property. Must be unique within its own component subgroup (nodes or edges). Must be a non-empty string.</p> required <code>dtype</code> <code>str</code> <p>Data type of the property. Must be one of the allowed string dtypes.</p> required <code>varlength</code> <code>bool</code> <p>True if the property contains variable length arrays. Variable length arrays cannot be of dtype string (e.g. you cannot have a property where each node has an array of strings)</p> <code>False</code> <code>unit</code> <code>str | None</code> <p>Optional unit of the property.</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Optional human friendly name of the property</p> <code>None</code> <code>description</code> <code>str | None</code> <p>Optional description of the property.</p> <code>None</code>"},{"location":"reference/geff_spec/#geff_spec.RelatedObject","title":"RelatedObject","text":"<p>               Bases: <code>BaseModel</code></p> <p>A set of metadata for data that is associated with the graph. The types 'labels' and 'image' should be used for label and image objects, respectively. Other types are also allowed.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str</code> <p>Type of the related object. 'labels' for label objects, 'image' for image objects. Other types are also allowed, but may not be recognized by reader applications.</p> required <code>path</code> <code>str</code> <p>Path of the related object within the zarr group, relative to the geff zarr-attributes file. It is strongly recommended all related objects are stored as siblings of the geff group within the top-level zarr group.</p> required <code>label_prop</code> <code>str | None</code> <p>Property name for label objects. This is the node property that will be used to identify the labels in the related object. This is only valid for type 'labels'.</p> <code>None</code>"},{"location":"reference/geff_spec/#geff_spec.validate_axis_type","title":"validate_axis_type","text":"<pre><code>validate_axis_type(axis_type: Any) -&gt; TypeGuard[AxisType]\n</code></pre> <p>Validate axis type against standard list</p> <p>Parameters:</p> Name Type Description Default <code>axis_type</code> <code>str</code> <p>Axis type to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>TypeGuard[AxisType]</code> <p>False if the axis is not in valid types</p>"},{"location":"reference/geff_spec/#geff_spec.validate_space_unit","title":"validate_space_unit","text":"<pre><code>validate_space_unit(\n    unit_name: Any,\n) -&gt; TypeGuard[SpaceUnits]\n</code></pre> <p>Checks space unit against ome-zarr supported units</p> <p>Parameters:</p> Name Type Description Default <code>unit_name</code> <code>str</code> <p>Unit name to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>TypeGuard[SpaceUnits]</code> <p>True if a space unit is a KNOWN valid unit.</p> <code>TypeGuard[SpaceUnits]</code> <p>False if the unit is not known. The unit may be valid.</p>"},{"location":"reference/geff_spec/#geff_spec.validate_time_unit","title":"validate_time_unit","text":"<pre><code>validate_time_unit(unit_name: Any) -&gt; TypeGuard[TimeUnits]\n</code></pre> <p>Check time unit against ome-zarr supported units</p> <p>Parameters:</p> Name Type Description Default <code>unit_name</code> <code>str</code> <p>Unit name to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>TypeGuard[TimeUnits]</code> <p>True if a time unit is a KNOWN valid unit.</p> <code>TypeGuard[TimeUnits]</code> <p>False if the unit is not known. The unit may be valid.</p>"},{"location":"reference/geff_spec/utils/","title":"utils","text":""},{"location":"reference/geff_spec/utils/#geff_spec.utils","title":"geff_spec.utils","text":""},{"location":"reference/geff_spec/utils/#geff_spec.utils.add_or_update_props_metadata","title":"add_or_update_props_metadata","text":"<pre><code>add_or_update_props_metadata(\n    metadata: GeffMetadata,\n    props_md: Sequence[PropMetadata],\n    c_type: Literal[\"node\", \"edge\"],\n) -&gt; GeffMetadata\n</code></pre> <p>Create new props metadata or update existing metadata with new props metadata.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>GeffMetadata</code> <p>Existing metadata object</p> required <code>props_md</code> <code>Sequence[PropMetadata]</code> <p>The props metadata to add to the metadata.</p> required <code>c_type</code> <code>Literal['node', 'edge']</code> <p>The type of the props metadata.</p> required <p>Returns:</p> Type Description <code>GeffMetadata</code> <p>GeffMetadata object with updated props metadata.</p> Warning <p>If a key in props_md already exists in the properties metadata, it will be overwritten.</p>"},{"location":"reference/geff_spec/utils/#geff_spec.utils.axes_from_lists","title":"axes_from_lists","text":"<pre><code>axes_from_lists(\n    axis_names: Sequence[str] | None = None,\n    axis_units: Sequence[str | None] | None = None,\n    axis_types: Sequence[Literal[AxisType] | None]\n    | None = None,\n    axis_scales: Sequence[float | None] | None = None,\n    scaled_units: Sequence[str | None] | None = None,\n    axis_offset: Sequence[float | None] | None = None,\n    roi_min: Sequence[float | None] | None = None,\n    roi_max: Sequence[float | None] | None = None,\n) -&gt; list[Axis]\n</code></pre> <p>Create a list of Axes objects from lists of axis names, units, types, mins, and maxes. If axis_names is None, there are no spatial axes and the list will be empty. Nones for all other arguments will omit them from the axes.</p> <p>All provided arguments must have the same length. If an argument should not be specified for a single property, use None.</p> <p>Parameters:</p> Name Type Description Default <code>axis_names</code> <code>Sequence[str] | None</code> <p>Names of properties for spatiotemporal axes. Defaults to None.</p> <code>None</code> <code>axis_units</code> <code>Sequence[str | None] | None</code> <p>Units corresponding to named properties. Defaults to None.</p> <code>None</code> <code>axis_types</code> <code>Sequence[Literal[AxisType] | None] | None</code> <p>Axis type for each property. Choose from \"space\", \"time\", \"channel\". Defaults to None.</p> <code>None</code> <code>axis_scales</code> <code>(Sequence[float | None] | None, optional)</code> <p>The scale to apply to the spatial dims. Defaults to None.</p> <code>None</code> <code>scaled_units</code> <code>Sequence[str | None] | None</code> <p>The units of the spatial dims after scaling. Defaults to None.</p> <code>None</code> <code>axis_offset</code> <code>list[float | None] | None</code> <p>Amount to offset an axis after applying scaling factor. Defaults to None.</p> <code>None</code> <code>roi_min</code> <code>Sequence[float | None] | None</code> <p>Minimum value for each property. Defaults to None.</p> <code>None</code> <code>roi_max</code> <code>Sequence[float | None] | None</code> <p>Maximum value for each property. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Axis]</code> <p>list[Axis]: A list of axes objects, one per entry in axis_names</p>"},{"location":"reference/geff_spec/utils/#geff_spec.utils.compute_and_add_axis_min_max","title":"compute_and_add_axis_min_max","text":"<pre><code>compute_and_add_axis_min_max(\n    metadata: GeffMetadata,\n    node_props: dict[str, PropDictNpArray],\n) -&gt; GeffMetadata\n</code></pre> <p>Create a new metadata object with the min and max values for each axis added.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>GeffMetadata</code> <p>The metadata to update with the min and max axis values.</p> required <code>node_props</code> <code>dict[str, PropDictNpArray]</code> <p>The node props to compute the min and max from</p> required <p>Returns:</p> Name Type Description <code>GeffMetadata</code> <code>GeffMetadata</code> <p>A new metadata object with the min and max updated.</p>"},{"location":"reference/geff_spec/utils/#geff_spec.utils.create_or_update_metadata","title":"create_or_update_metadata","text":"<pre><code>create_or_update_metadata(\n    metadata: GeffMetadata | None,\n    is_directed: bool,\n    axes: Any = None,\n) -&gt; GeffMetadata\n</code></pre> <p>Create new metadata or update existing metadata with axes, version, and directedness.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>GeffMetadata | None</code> <p>Existing metadata object or None</p> required <code>is_directed</code> <code>bool</code> <p>Whether the graph is directed</p> required <code>axes</code> <code>Any</code> <p>The axes object to set</p> <code>None</code> <p>Returns:</p> Type Description <code>GeffMetadata</code> <p>Updated or new GeffMetadata object</p>"},{"location":"reference/geff_spec/utils/#geff_spec.utils.create_props_metadata","title":"create_props_metadata","text":"<pre><code>create_props_metadata(\n    identifier: str,\n    prop_data: PropDictNpArray,\n    unit: str | None = None,\n    name: str | None = None,\n    description: str | None = None,\n) -&gt; PropMetadata\n</code></pre> <p>Create PropMetadata from property data.</p> <p>Automatically detects dtype and varlength from the provided data. If dtype is float16, upcasts to float32 with warning.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>str</code> <p>The property identifier/name</p> required <code>prop_data</code> <code>PropDictNpArray</code> <p>The property to generate metadata for</p> required <code>unit</code> <code>str</code> <p>Optional unit for the property</p> <code>None</code> <code>name</code> <code>str</code> <p>Optional human-friendly name for the property</p> <code>None</code> <code>description</code> <code>str</code> <p>Optional description for the property</p> <code>None</code> <p>Returns:</p> Type Description <code>PropMetadata</code> <p>PropMetadata object with inferred dtype and varlength settings</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If var length array has mixed dtype</p>"},{"location":"reference/geff_spec/utils/#geff_spec.utils.update_metadata_axes","title":"update_metadata_axes","text":"<pre><code>update_metadata_axes(\n    metadata: GeffMetadata,\n    axis_names: list[str],\n    axis_units: list[str | None] | None = None,\n    axis_types: list[Literal[AxisType] | None]\n    | None = None,\n    axis_scales: list[float | None] | None = None,\n    scaled_units: list[str | None] | None = None,\n    axis_offset: list[float | None] | None = None,\n) -&gt; GeffMetadata\n</code></pre> <p>Update the axis names, units, and types in a geff metadata object. Overrides any existing axes.</p> <p>If axis lists are provided, they will override the graph properties and metadata. If metadata is provided, it will override the graph properties. If neither are provided, the graph properties will be used.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>GeffMetadata</code> <p>The metadata of the graph.</p> required <code>axis_names</code> <code>list[str]</code> <p>The names of the spatial dims.</p> required <code>axis_units</code> <code>list[str | None] | None</code> <p>The units of the spatial dims. Defaults to None.</p> <code>None</code> <code>axis_types</code> <code>list[Literal[AxisType] | None] | None</code> <p>The types of the spatial dims. Defaults to None.</p> <code>None</code> <code>axis_scales</code> <code>list[float | None] | None</code> <p>The scale to apply to the spatial dims. Defaults to None.</p> <code>None</code> <code>scaled_units</code> <code>list[str | None] | None</code> <p>The units of the spatial dims after scaling. Defaults to None.</p> <code>None</code> <code>axis_offset</code> <code>list[float | None] | None</code> <p>Amount to offset an axis after applying scaling factor. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>GeffMetadata</code> <code>GeffMetadata</code> <p>A new metadata object with updated axes.</p>"}]}